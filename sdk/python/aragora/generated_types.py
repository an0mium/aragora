"""
Auto-generated Pydantic models from OpenAPI specification.

DO NOT EDIT - This file is auto-generated by scripts/generate_python_sdk_types.py
To regenerate: python scripts/generate_python_sdk_types.py

Generated from: docs/api/openapi.json
"""

# generated by datamodel-codegen:
#   filename:  openapi.json

from __future__ import annotations

from datetime import date as date_aliased
from datetime import datetime
from enum import StrEnum
from typing import Annotated, Any

from pydantic import AnyUrl, BaseModel, Extra, Field


class Code(StrEnum):
    INVALID_JSON = "INVALID_JSON"
    MISSING_FIELD = "MISSING_FIELD"
    INVALID_VALUE = "INVALID_VALUE"
    AUTH_REQUIRED = "AUTH_REQUIRED"
    INVALID_TOKEN = "INVALID_TOKEN"
    FORBIDDEN = "FORBIDDEN"
    NOT_OWNER = "NOT_OWNER"
    NOT_FOUND = "NOT_FOUND"
    QUOTA_EXCEEDED = "QUOTA_EXCEEDED"
    RATE_LIMITED = "RATE_LIMITED"
    INTERNAL_ERROR = "INTERNAL_ERROR"
    SERVICE_UNAVAILABLE = "SERVICE_UNAVAILABLE"
    AGENT_TIMEOUT = "AGENT_TIMEOUT"
    CONSENSUS_FAILED = "CONSENSUS_FAILED"


class Error(BaseModel):
    error: Annotated[
        str,
        Field(
            description="Human-readable error message",
            example="Invalid request: missing required field 'task'",
        ),
    ]
    code: Annotated[
        Code | None,
        Field(
            description="Machine-readable error code for programmatic handling",
            example="MISSING_FIELD",
        ),
    ] = None
    trace_id: Annotated[
        str | None,
        Field(
            description="Unique request ID for debugging and support", example="req_abc123xyz789"
        ),
    ] = None
    field: Annotated[
        str | None,
        Field(
            description="Name of the field that caused the error (for validation errors)",
            example="task",
        ),
    ] = None
    resource_type: Annotated[
        str | None,
        Field(description="Type of resource involved in the error", example="debate"),
    ] = None
    resource_id: Annotated[
        str | None,
        Field(description="ID of the resource involved in the error", example="deb_abc123"),
    ] = None
    limit: Annotated[
        int | None,
        Field(description="The limit that was exceeded (for quota/rate errors)", example=60),
    ] = None
    retry_after: Annotated[
        int | None,
        Field(description="Seconds to wait before retrying (for rate limit errors)", example=45),
    ] = None
    resets_at: Annotated[
        datetime | None,
        Field(description="When the quota/rate limit resets", example="2024-01-16T00:00:00Z"),
    ] = None
    upgrade_url: Annotated[
        AnyUrl | None,
        Field(
            description="URL to upgrade plan (for quota errors)",
            example="https://aragora.ai/pricing",
        ),
    ] = None
    support_url: Annotated[
        AnyUrl | None,
        Field(
            description="URL for support/issue reporting",
            example="https://github.com/anthropics/aragora/issues",
        ),
    ] = None


class PaginatedResponse(BaseModel):
    total: Annotated[int | None, Field(description="Total items available")] = None
    offset: Annotated[int | None, Field(description="Current offset")] = None
    limit: Annotated[int | None, Field(description="Page size")] = None
    has_more: Annotated[bool | None, Field(description="More items available")] = None


class StandardSuccessResponse(BaseModel):
    success: bool
    data: dict[str, Any] | None = None
    message: str | None = None


class Agent(BaseModel):
    name: Annotated[str | None, Field(description="Agent name")] = None
    elo: Annotated[float | None, Field(description="ELO rating")] = None
    matches: Annotated[int | None, Field(description="Total matches played")] = None
    wins: Annotated[int | None, Field(description="Total wins")] = None
    losses: Annotated[int | None, Field(description="Total losses")] = None
    calibration_score: Annotated[float | None, Field(description="Calibration accuracy (0-1)")] = (
        None
    )


class Status(StrEnum):
    healthy = "healthy"
    degraded = "degraded"
    unhealthy = "unhealthy"


class HealthCheck(BaseModel):
    status: Status | None = None
    version: str | None = None
    timestamp: datetime | None = None
    checks: dict[str, dict[str, Any]] | None = None
    response_time_ms: float | None = None


class StarterTemplate(BaseModel):
    id: Annotated[str, Field(description="Unique template identifier")]
    name: Annotated[str, Field(description="Display name")]
    description: Annotated[str, Field(description="Template description")]
    use_cases: Annotated[list[str], Field(description="Applicable use cases")]
    agents_count: Annotated[int, Field(description="Number of agents")]
    rounds: Annotated[int, Field(description="Number of debate rounds")]
    estimated_minutes: Annotated[int, Field(description="Estimated duration")]
    example_prompt: Annotated[str, Field(description="Example prompt")]
    tags: Annotated[list[str] | None, Field(description="Categorization tags")] = None
    difficulty: Annotated[str | None, Field(description="Difficulty level")] = None


class Status1(StrEnum):
    pending = "pending"
    running = "running"
    completed = "completed"
    failed = "failed"


class GauntletRun(BaseModel):
    id: Annotated[str, Field(description="Run identifier")]
    status: Annotated[Status1, Field(description="Run status")]
    verdict: Annotated[str | None, Field(description="Final verdict")] = None
    confidence: Annotated[float | None, Field(description="Confidence score")] = None
    findings: Annotated[list[dict[str, Any]] | None, Field(description="List of findings")] = None
    metadata: Annotated[dict[str, Any] | None, Field(description="Additional metadata")] = None
    created_at: Annotated[datetime | None, Field(description="Creation timestamp")] = None
    started_at: Annotated[datetime | None, Field(description="Start timestamp")] = None
    completed_at: Annotated[datetime | None, Field(description="Completion timestamp")] = None


class GauntletComparison(BaseModel):
    run_a: GauntletRun | None = None
    run_b: GauntletRun | None = None
    diff: Annotated[dict[str, Any] | None, Field(description="Differences between runs")] = None
    similarity_score: Annotated[float | None, Field(description="Similarity percentage")] = None
    comparison_notes: Annotated[list[str] | None, Field(description="Notes about differences")] = (
        None
    )


class Policy(BaseModel):
    id: Annotated[str, Field(description="Policy identifier")]
    name: Annotated[str, Field(description="Policy name")]
    description: Annotated[str | None, Field(description="Policy description")] = None
    type: Annotated[str | None, Field(description="Policy type")] = None
    rules: Annotated[list[dict[str, Any]] | None, Field(description="Policy rules")] = None
    enabled: Annotated[bool | None, Field(description="Whether policy is enabled")] = None
    priority: Annotated[int | None, Field(description="Execution priority")] = None
    created_at: Annotated[datetime | None, Field(description="Creation timestamp")] = None
    updated_at: Annotated[datetime | None, Field(description="Last update timestamp")] = None


class DebateStatus(StrEnum):
    created = "created"
    starting = "starting"
    pending = "pending"
    running = "running"
    in_progress = "in_progress"
    completed = "completed"
    failed = "failed"
    cancelled = "cancelled"
    paused = "paused"
    active = "active"
    concluded = "concluded"
    archived = "archived"


class ConsensusResult(BaseModel):
    reached: bool | None = None
    agreement: float | None = None
    confidence: float | None = None
    final_answer: str | None = None
    conclusion: str | None = None
    supporting_agents: list[str] | None = None
    dissenting_agents: list[str] | None = None


class Agents(BaseModel):
    provider: str
    model: str | None = None
    persona: str | None = None
    role: str | None = None
    name: str | None = None
    hierarchy_role: str | None = None


class Consensus(StrEnum):
    majority = "majority"
    unanimous = "unanimous"
    supermajority = "supermajority"
    weighted = "weighted"
    hybrid = "hybrid"
    judge = "judge"
    none = "none"


class DebateFormat(StrEnum):
    light = "light"
    full = "full"


class AutoSelectConfig(BaseModel):
    primary_domain: str | None = "general"
    secondary_domains: list[str] | None = None
    required_traits: list[str] | None = None
    min_agents: int | None = 2
    max_agents: int | None = 4
    quality_priority: float | None = 0.7
    diversity_preference: float | None = 0.5


class TrendingCategory(StrEnum):
    tech = "tech"
    science = "science"
    politics = "politics"
    business = "business"
    health = "health"


class DebateCreateRequest(BaseModel):
    task: Annotated[
        str,
        Field(
            description="The topic or question for the debate",
            example="Should we adopt microservices architecture for our e-commerce platform?",
            max_length=2000,
            min_length=10,
        ),
    ]
    question: Annotated[
        str | None,
        Field(deprecated=True, description="Alias for task (deprecated, use task instead)"),
    ] = None
    agents: Annotated[
        list[str | Agents] | None,
        Field(
            description="List of agent specs to participate. If empty, auto_select is used.",
            example=["claude", "gpt-4", "gemini"],
            max_items=8,
            min_items=0,
        ),
    ] = None
    rounds: Annotated[
        int | None,
        Field(description="Maximum number of debate rounds", example=9, ge=1, le=12),
    ] = 9
    consensus: Annotated[
        Consensus | None,
        Field(description="Consensus strategy to use", example="judge"),
    ] = "judge"
    context: Annotated[
        str | None,
        Field(
            description="Additional context or background information",
            example="We have 1M daily active users and need 99.9% uptime.",
            max_length=10000,
        ),
    ] = None
    debate_format: Annotated[DebateFormat | None, Field(description="Debate protocol preset")] = (
        "full"
    )
    documents: Annotated[
        list[str] | None,
        Field(
            description="Document IDs to ground the debate in uploaded files",
            example=["doc-123", "doc-456"],
            max_items=50,
            min_items=1,
        ),
    ] = None
    document_ids: Annotated[
        list[str] | None,
        Field(deprecated=True, description="Alias for documents (deprecated)"),
    ] = None
    auto_select: Annotated[
        bool | None,
        Field(
            description="Automatically select optimal agents based on topic (used when agents is empty)"
        ),
    ] = False
    auto_select_config: Annotated[
        AutoSelectConfig | None,
        Field(description="Configuration for auto-selection algorithm"),
    ] = None
    enable_verticals: Annotated[
        bool | None,
        Field(
            description="Enable vertical specialist injection for the task domain (default set by ARAGORA_ENABLE_VERTICALS)"
        ),
    ] = True
    vertical_id: Annotated[
        str | None,
        Field(description="Explicit vertical ID to inject (e.g., software, legal, healthcare)"),
    ] = None
    use_trending: Annotated[
        bool | None,
        Field(description="Include trending context from news/social media"),
    ] = False
    trending_category: Annotated[
        TrendingCategory | None,
        Field(description="Category filter for trending content"),
    ] = None
    metadata: Annotated[
        dict[str, Any] | None,
        Field(description="Optional metadata for tracking and integrations"),
    ] = None


class DebateCreateResponse(BaseModel):
    success: Annotated[
        bool,
        Field(description="Whether the debate was created successfully", example=True),
    ]
    debate_id: Annotated[
        str | None,
        Field(description="Unique identifier for the created debate", example="deb_abc123xyz"),
    ] = None
    status: Annotated[DebateStatus | None, Field(description="Current status of the debate")] = None
    task: Annotated[
        str | None,
        Field(
            description="The debate topic (echoed back)",
            example="Should we adopt microservices architecture?",
        ),
    ] = None
    agents: Annotated[
        list[str] | None,
        Field(
            description="Agents participating in the debate", example=["claude", "gpt-4", "gemini"]
        ),
    ] = None
    websocket_url: Annotated[
        str | None,
        Field(
            description="WebSocket URL to stream debate progress",
            example="wss://api.aragora.ai/ws/debates/deb_abc123xyz",
        ),
    ] = None
    estimated_duration: Annotated[
        int | None,
        Field(description="Estimated debate duration in seconds", example=120),
    ] = None
    error: Annotated[str | None, Field(description="Error message if success is false")] = None


class Role(StrEnum):
    system = "system"
    user = "user"
    assistant = "assistant"


class Message(BaseModel):
    role: Role | None = None
    content: str | None = None
    agent: str | None = None
    agent_id: str | None = None
    round: int | None = None
    timestamp: datetime | None = None


class Round(BaseModel):
    round_number: Annotated[int | None, Field(description="Round number (1-indexed)")] = None
    messages: list[Message] | None = None
    votes: Annotated[dict[str, Any] | None, Field(description="Agent votes for this round")] = None
    summary: Annotated[str | None, Field(description="Round summary")] = None


class Consensus1(BaseModel):
    reached: bool | None = None
    topic: str | None = None
    verdict: str | None = None
    confidence: float | None = None
    participating_agents: list[str] | None = None


class SimilarDebate(BaseModel):
    debate_id: str | None = None
    topic: str | None = None
    similarity_score: Annotated[float | None, Field(description="0-1 similarity")] = None
    verdict: str | None = None
    created_at: datetime | None = None
    agents: list[str] | None = None


class SimilarDebatesResponse(BaseModel):
    debates: list[SimilarDebate] | None = None
    query: str | None = None
    total: int | None = None


class SettledQuestion(BaseModel):
    question: str | None = None
    answer: str | None = None
    confidence: float | None = None
    debate_count: int | None = None
    last_debated: datetime | None = None
    supporting_debates: list[str] | None = None


class SettledQuestionsResponse(BaseModel):
    questions: list[SettledQuestion] | None = None
    total: int | None = None
    threshold: float | None = None


class ByDomain(BaseModel):
    count: int | None = None
    consensus_rate: float | None = None


class ConsensusStats(BaseModel):
    total_debates: int | None = None
    consensus_rate: float | None = None
    avg_time_to_consensus_ms: int | None = None
    avg_rounds_to_consensus: float | None = None
    by_domain: dict[str, ByDomain] | None = None


class DissentingView(BaseModel):
    debate_id: str | None = None
    agent: str | None = None
    position: str | None = None
    reasoning: str | None = None
    strength_score: float | None = None
    created_at: datetime | None = None


class DissentingViewsResponse(BaseModel):
    dissents: list[DissentingView] | None = None
    total: int | None = None


class ContrarianView(BaseModel):
    topic: str | None = None
    consensus_position: str | None = None
    contrarian_position: str | None = None
    agent: str | None = None
    argument_strength: float | None = None


class ContrarianViewsResponse(BaseModel):
    views: list[ContrarianView] | None = None
    total: int | None = None


class Type(StrEnum):
    low_confidence = "low_confidence"
    shifting = "shifting"
    contradictory = "contradictory"
    bias = "bias"


class Severity(StrEnum):
    low = "low"
    medium = "medium"
    high = "high"


class RiskWarning(BaseModel):
    type: Type | None = None
    topic: str | None = None
    description: str | None = None
    severity: Severity | None = None
    debate_ids: list[str] | None = None


class RiskWarningsResponse(BaseModel):
    warnings: list[RiskWarning] | None = None
    total: int | None = None


class TopAgent(BaseModel):
    agent: str | None = None
    contribution_count: int | None = None


class DomainConsensusResponse(BaseModel):
    domain: str | None = None
    total_debates: int | None = None
    consensus_rate: float | None = None
    settled_questions: list[SettledQuestion] | None = None
    top_agents: list[TopAgent] | None = None


class DebateSummary(BaseModel):
    debate_id: str
    summary: str
    confidence: float | None = None
    consensus_reached: bool | None = None


class BeliefCrux(BaseModel):
    id: str | None = None
    proposition: Annotated[str | None, Field(description="The crux proposition")] = None
    importance: Annotated[float | None, Field(description="Importance score 0-1")] = None
    agents_for: list[str] | None = None
    agents_against: list[str] | None = None
    resolution_impact: Annotated[
        str | None, Field(description="How resolving this crux would affect the debate")
    ] = None


class BeliefCruxesResponse(BaseModel):
    debate_id: str | None = None
    cruxes: list[BeliefCrux] | None = None
    total: int | None = None


class LoadBearingClaim(BaseModel):
    id: str | None = None
    claim: str | None = None
    agent: str | None = None
    dependents_count: Annotated[
        int | None, Field(description="Number of arguments that depend on this claim")
    ] = None
    confidence: float | None = None
    evidence: list[str] | None = None


class LoadBearingClaimsResponse(BaseModel):
    debate_id: str | None = None
    claims: list[LoadBearingClaim] | None = None
    total: int | None = None


class MostConnectedClaim(BaseModel):
    claim: str | None = None
    connections: int | None = None


class BeliefGraphStats(BaseModel):
    debate_id: str | None = None
    node_count: int | None = None
    edge_count: int | None = None
    max_depth: int | None = None
    clustering_coefficient: float | None = None
    most_connected_claims: list[MostConnectedClaim] | None = None


class Calibration(BaseModel):
    agent: str | None = None
    score: Annotated[float | None, Field(description="Calibration score (0-1)")] = None
    bucket_stats: list[dict[str, Any]] | None = None
    overconfidence_index: float | None = None


class Relationship(BaseModel):
    agent_a: str | None = None
    agent_b: str | None = None
    alliance_score: float | None = None
    rivalry_score: float | None = None
    total_interactions: int | None = None


class OAuthProvider(BaseModel):
    id: Annotated[str, Field(description="Provider identifier (e.g., 'google', 'github')")]
    name: Annotated[str, Field(description="Display name for the provider")]


class OAuthProviders(BaseModel):
    providers: Annotated[
        list[OAuthProvider], Field(description="List of available OAuth providers")
    ]


class Workspace(BaseModel):
    id: Annotated[str, Field(description="Workspace ID")]
    organization_id: Annotated[str, Field(description="Parent organization ID")]
    name: Annotated[str, Field(description="Workspace name")]
    created_at: datetime | None = None
    created_by: str | None = None
    encrypted: Annotated[bool | None, Field(description="Whether workspace data is encrypted")] = (
        None
    )
    retention_days: Annotated[int | None, Field(description="Data retention period in days")] = None
    sensitivity_level: Annotated[str | None, Field(description="Data sensitivity level")] = None
    document_count: int | None = None
    storage_bytes: int | None = None


class WorkspaceList(BaseModel):
    workspaces: list[Workspace]
    total: int


class RetentionPolicy(BaseModel):
    id: str | None = None
    name: str | None = None
    retention_days: int | None = None
    data_types: list[str] | None = None
    enabled: bool | None = None
    created_at: datetime | None = None


class RetentionPolicyList(BaseModel):
    policies: list[RetentionPolicy] | None = None
    total: int | None = None


class StepDefinition(BaseModel):
    id: str | None = None
    name: str | None = None
    type: str | None = None
    config: dict[str, Any] | None = None
    depends_on: list[str] | None = None


class TransitionRule(BaseModel):
    from_step: str | None = None
    to_step: str | None = None
    condition: str | None = None


class Workflow(BaseModel):
    id: str | None = None
    name: str | None = None
    description: str | None = None
    version: str | None = None
    status: str | None = None
    steps: list[StepDefinition] | None = None
    transitions: list[TransitionRule] | None = None
    created_at: datetime | None = None
    updated_at: datetime | None = None


class WorkflowList(BaseModel):
    workflows: list[Workflow] | None = None
    total: int | None = None


class WorkflowUpdate(BaseModel):
    name: str | None = None
    description: str | None = None
    steps: list[StepDefinition] | None = None
    transitions: list[TransitionRule] | None = None


class WorkflowTemplate(BaseModel):
    id: str | None = None
    name: str | None = None
    description: str | None = None
    category: str | None = None
    steps: list[StepDefinition] | None = None
    parameters: dict[str, Any] | None = None


class WorkflowTemplateList(BaseModel):
    templates: list[WorkflowTemplate] | None = None
    total: int | None = None


class ExecutionList(BaseModel):
    executions: list[dict[str, Any]] | None = None
    total: int | None = None


class DecisionReceipt(BaseModel):
    id: Annotated[str, Field(description="Receipt ID")]
    debate_id: Annotated[str, Field(description="Associated debate ID")]
    verdict: Annotated[str, Field(description="Final verdict")]
    confidence: Annotated[float | None, Field(description="Confidence score (0-1)")] = None
    consensus_reached: bool | None = None
    participating_agents: list[str] | None = None
    dissenting_agents: list[str] | None = None
    evidence: list[dict[str, Any]] | None = None
    reasoning: str | None = None
    hash: Annotated[str | None, Field(description="Receipt integrity hash")] = None
    created_at: datetime | None = None
    metadata: dict[str, Any] | None = None


class ReceiptList(BaseModel):
    receipts: list[DecisionReceipt]
    total: int
    offset: int | None = None
    limit: int | None = None
    has_more: bool | None = None


class RiskHeatmap(BaseModel):
    id: Annotated[str, Field(description="Heatmap ID")]
    gauntlet_id: Annotated[str | None, Field(description="Associated gauntlet ID")] = None
    categories: Annotated[list[str], Field(description="Risk categories")]
    scores: Annotated[list[float], Field(description="Risk scores per category")]
    matrix: Annotated[list[list[float]] | None, Field(description="2D risk matrix")] = None
    overall_risk: Annotated[float | None, Field(description="Overall risk score")] = None
    created_at: datetime | None = None
    metadata: dict[str, Any] | None = None


class HeatmapList(BaseModel):
    heatmaps: list[RiskHeatmap]
    total: int
    offset: int | None = None
    limit: int | None = None


class PatternType(StrEnum):
    hive_mind = "hive_mind"
    map_reduce = "map_reduce"
    review_cycle = "review_cycle"


class PatternTemplate(BaseModel):
    id: Annotated[str, Field(description="Pattern template ID")]
    name: Annotated[str, Field(description="Pattern name")]
    description: Annotated[str | None, Field(description="Pattern description")] = None
    pattern_type: PatternType
    parameters: Annotated[dict[str, Any] | None, Field(description="Pattern parameters schema")] = (
        None
    )
    example_config: Annotated[dict[str, Any] | None, Field(description="Example configuration")] = (
        None
    )
    created_at: datetime | None = None


class PatternTemplateList(BaseModel):
    templates: list[PatternTemplate]
    total: int


class CheckpointMetadata(BaseModel):
    id: Annotated[str, Field(description="Checkpoint ID")]
    debate_id: Annotated[str | None, Field(description="Associated debate ID")] = None
    workflow_id: Annotated[str | None, Field(description="Associated workflow ID")] = None
    name: Annotated[str | None, Field(description="Checkpoint name")] = None
    description: str | None = None
    state: Annotated[dict[str, Any] | None, Field(description="Checkpoint state data")] = None
    round_number: int | None = None
    created_at: datetime
    created_by: str | None = None
    size_bytes: int | None = None


class CheckpointList(BaseModel):
    checkpoints: list[CheckpointMetadata]
    total: int
    offset: int | None = None
    limit: int | None = None


class RestoreResult(BaseModel):
    success: bool
    checkpoint_id: str
    debate_id: str | None = None
    workflow_id: str | None = None
    restored_at: datetime | None = None
    state_restored: bool | None = None
    message: str | None = None


class Factor(BaseModel):
    name: str | None = None
    contribution: float | None = None
    description: str | None = None
    type: str | None = None


class Counterfactual(BaseModel):
    scenario: str | None = None
    outcome: str | None = None
    probability: float | None = None


class ProvenanceItem(BaseModel):
    step: int | None = None
    action: str | None = None
    agent: str | None = None
    confidence: float | None = None
    timestamp: datetime | None = None


class DecisionExplanation(BaseModel):
    debate_id: Annotated[str, Field(description="Debate ID")]
    narrative: Annotated[str, Field(description="Natural language narrative")]
    confidence: Annotated[float | None, Field(description="Overall confidence (0-1)")] = None
    factors: Annotated[list[Factor] | None, Field(description="Contributing factors")] = None
    counterfactuals: Annotated[
        list[Counterfactual] | None, Field(description="What-if scenarios")
    ] = None
    provenance: Annotated[
        list[ProvenanceItem] | None, Field(description="Decision provenance chain")
    ] = None
    generated_at: datetime | None = None


class EvidenceLink(BaseModel):
    id: str
    content: str
    source: str
    relevance_score: float
    quality_scores: dict[str, Any] | None = None
    cited_by: list[str] | None = None
    grounding_type: str | None = None
    timestamp: datetime | None = None
    metadata: dict[str, Any] | None = None


class EvidenceChain(BaseModel):
    debate_id: str
    evidence_count: int
    evidence_quality_score: float | None = None
    evidence: list[EvidenceLink]


class VotePivot(BaseModel):
    agent: str
    choice: str
    confidence: float
    weight: float
    reasoning_summary: str
    influence_score: float | None = None
    calibration_adjustment: float | None = None
    elo_rating: float | None = None
    flip_detected: bool | None = None
    metadata: dict[str, Any] | None = None


class VotePivots(BaseModel):
    debate_id: str
    total_votes: int | None = None
    pivotal_votes: int | None = None
    agent_agreement_score: float | None = None
    votes: list[VotePivot]


class Counterfactual1(BaseModel):
    condition: str
    outcome_change: str
    likelihood: float
    sensitivity: float
    affected_agents: list[str] | None = None
    metadata: dict[str, Any] | None = None


class Counterfactuals(BaseModel):
    debate_id: str
    counterfactual_count: int | None = None
    counterfactuals: list[Counterfactual1]


class ExplainabilityBatch(BaseModel):
    batch_id: str
    status: str
    total_debates: int
    status_url: str | None = None
    results_url: str | None = None


class ExplainabilityBatchStatus(BaseModel):
    batch_id: str
    status: str
    total_debates: int
    processed_count: int | None = None
    success_count: int | None = None
    error_count: int | None = None
    created_at: float | None = None
    started_at: float | None = None
    completed_at: float | None = None
    progress_pct: float | None = None


class BatchDebateResult(BaseModel):
    debate_id: str
    status: str
    processing_time_ms: float | None = None
    explanation: dict[str, Any] | None = None
    error: str | None = None


class Pagination(BaseModel):
    offset: int | None = None
    limit: int | None = None
    total: int | None = None
    has_more: bool | None = None


class ExplainabilityBatchResults(BaseModel):
    batch_id: str
    status: str
    total_debates: int
    processed_count: int | None = None
    success_count: int | None = None
    error_count: int | None = None
    created_at: float | None = None
    started_at: float | None = None
    completed_at: float | None = None
    progress_pct: float | None = None
    results: list[BatchDebateResult]
    pagination: Pagination | None = None


class ControlPlaneAgent(BaseModel):
    agent_id: str
    capabilities: list[str]
    status: str
    model: str | None = None
    provider: str | None = None
    metadata: dict[str, Any] | None = None
    registered_at: float | None = None
    last_heartbeat: float | None = None
    current_task_id: str | None = None
    tasks_completed: int | None = None
    tasks_failed: int | None = None
    avg_latency_ms: float | None = None
    region_id: str | None = None
    available_regions: list[str] | None = None
    region_latency_ms: dict[str, Any] | None = None
    last_heartbeat_by_region: dict[str, Any] | None = None


class ControlPlaneAgentList(BaseModel):
    agents: list[ControlPlaneAgent]
    total: int


class ControlPlaneTask(BaseModel):
    id: str
    task_type: str
    payload: dict[str, Any] | None = None
    required_capabilities: list[str] | None = None
    status: str
    priority: str | None = None
    created_at: float | None = None
    assigned_at: float | None = None
    started_at: float | None = None
    completed_at: float | None = None
    assigned_agent: str | None = None
    timeout_seconds: float | None = None
    max_retries: int | None = None
    retries: int | None = None
    result: dict[str, Any] | None = None
    error: str | None = None
    metadata: dict[str, Any] | None = None
    target_region: str | None = None
    fallback_regions: list[str] | None = None
    assigned_region: str | None = None
    region_routing_mode: str | None = None
    origin_region: str | None = None


class ControlPlaneTaskCreated(BaseModel):
    task_id: str


class ControlPlaneTaskClaimResponse(BaseModel):
    task: ControlPlaneTask | None = None


class ControlPlaneQueueJob(BaseModel):
    id: str | None = None
    type: str | None = None
    name: str | None = None
    status: str | None = None
    progress: float | None = None
    started_at: str | None = None
    created_at: str | None = None
    document_count: int | None = None
    agents_assigned: list[str] | None = None
    priority: str | None = None


class ControlPlaneQueue(BaseModel):
    jobs: list[ControlPlaneQueueJob]
    total: int


class ControlPlaneMetrics(BaseModel):
    active_jobs: int | None = None
    queued_jobs: int | None = None
    completed_jobs: int | None = None
    agents_available: int | None = None
    agents_busy: int | None = None
    total_agents: int | None = None
    documents_processed_today: int | None = None
    audits_completed_today: int | None = None
    tokens_used_today: int | None = None


class ControlPlaneStats(BaseModel):
    scheduler: dict[str, Any] | None = None
    registry: dict[str, Any] | None = None


class ControlPlaneHealth(BaseModel):
    status: str | None = None
    agents: dict[str, Any] | None = None


class AgentRegistration(BaseModel):
    agent_id: str | None = None
    capabilities: list[str] | None = None
    model: str | None = None
    provider: str | None = None
    registered_at: datetime | None = None
    status: str | None = None


class TaskStatus(BaseModel):
    task_id: str | None = None
    status: str | None = None
    progress: float | None = None
    started_at: datetime | None = None
    completed_at: datetime | None = None
    result: dict[str, Any] | None = None
    error: str | None = None


class PolicyEvaluation(BaseModel):
    policy_id: str | None = None
    allowed: bool | None = None
    reason: str | None = None
    conditions_met: list[str] | None = None
    evaluated_at: datetime | None = None


class VulnerabilityReference(BaseModel):
    url: str | None = None
    source: str | None = None
    tags: list[str] | None = None


class VulnerabilityFinding(BaseModel):
    id: str | None = None
    title: str | None = None
    description: str | None = None
    severity: str | None = None
    cvss_score: float | None = None
    package_name: str | None = None
    package_ecosystem: str | None = None
    vulnerable_versions: list[str] | None = None
    patched_versions: list[str] | None = None
    source: str | None = None
    references: list[VulnerabilityReference] | None = None
    cwe_ids: list[str] | None = None
    fix_available: bool | None = None
    recommended_version: str | None = None


class DependencyInfo(BaseModel):
    name: str | None = None
    version: str | None = None
    ecosystem: str | None = None
    direct: bool | None = None
    dev_dependency: bool | None = None
    license: str | None = None
    vulnerabilities: list[VulnerabilityFinding] | None = None
    has_vulnerabilities: bool | None = None
    highest_severity: str | None = None


class CodebaseScanSummary(BaseModel):
    total_dependencies: int | None = None
    vulnerable_dependencies: int | None = None
    critical_count: int | None = None
    high_count: int | None = None
    medium_count: int | None = None
    low_count: int | None = None


class CodebaseScanResult(BaseModel):
    scan_id: str | None = None
    repository: str | None = None
    branch: str | None = None
    commit_sha: str | None = None
    started_at: datetime | None = None
    completed_at: datetime | None = None
    status: str | None = None
    error: str | None = None
    dependencies: list[DependencyInfo] | None = None
    vulnerabilities: list[VulnerabilityFinding] | None = None
    summary: CodebaseScanSummary | None = None


class CodebaseScanStartResponse(BaseModel):
    success: bool | None = None
    scan_id: str | None = None
    status: str | None = None
    repository: str | None = None


class CodebaseScanResultResponse(BaseModel):
    success: bool | None = None
    scan_result: CodebaseScanResult | None = None


class CodebaseScanListResponse(BaseModel):
    success: bool | None = None
    scans: list[dict[str, Any]] | None = None
    total: int | None = None
    limit: int | None = None
    offset: int | None = None


class CodebaseVulnerabilityListResponse(BaseModel):
    success: bool | None = None
    vulnerabilities: list[VulnerabilityFinding] | None = None
    total: int | None = None
    limit: int | None = None
    offset: int | None = None
    scan_id: str | None = None


class CodebasePackageVulnerabilityResponse(BaseModel):
    success: bool | None = None
    package: str | None = None
    ecosystem: str | None = None
    version: str | None = None
    vulnerabilities: list[VulnerabilityFinding] | None = None
    total: int | None = None


class CodebaseCVEResponse(BaseModel):
    success: bool | None = None
    vulnerability: VulnerabilityFinding | None = None


class CodebaseMetricsStartResponse(BaseModel):
    success: bool | None = None
    analysis_id: str | None = None
    status: str | None = None
    repository: str | None = None


class CodebaseMetricsReportResponse(BaseModel):
    success: bool | None = None
    report: dict[str, Any] | None = None


class CodebaseHotspot(BaseModel):
    file_path: str | None = None
    function_name: str | None = None
    class_name: str | None = None
    start_line: int | None = None
    end_line: int | None = None
    complexity: float | None = None
    lines_of_code: int | None = None
    risk_score: float | None = None


class CodebaseHotspotListResponse(BaseModel):
    success: bool | None = None
    hotspots: list[CodebaseHotspot] | None = None
    total: int | None = None
    analysis_id: str | None = None


class CodebaseDuplicateListResponse(BaseModel):
    success: bool | None = None
    duplicates: list[dict[str, Any]] | None = None
    total: int | None = None
    analysis_id: str | None = None


class CodebaseFileMetricsResponse(BaseModel):
    success: bool | None = None
    file: dict[str, Any] | None = None
    analysis_id: str | None = None


class CodebaseMetricsHistoryResponse(BaseModel):
    success: bool | None = None
    analyses: list[dict[str, Any]] | None = None
    total: int | None = None
    limit: int | None = None
    offset: int | None = None


class CodebaseDependencyAnalysisRequest(BaseModel):
    repository: str
    branch: str | None = None
    include_dev: bool | None = None
    ecosystems: list[str] | None = None


class CodebaseDependencyAnalysisResponse(BaseModel):
    success: bool | None = None
    analysis_id: str | None = None
    status: str | None = None


class CodebaseDependencyScanRequest(BaseModel):
    repository: str
    branch: str | None = None
    severity_threshold: str | None = None


class CodebaseDependencyScanResponse(BaseModel):
    success: bool | None = None
    scan_id: str | None = None
    status: str | None = None


class CodebaseLicenseCheckRequest(BaseModel):
    repository: str
    branch: str | None = None
    allowed_licenses: list[str] | None = None
    blocked_licenses: list[str] | None = None


class CodebaseLicenseCheckResponse(BaseModel):
    success: bool | None = None
    check_id: str | None = None
    status: str | None = None


class Format(StrEnum):
    spdx = "spdx"
    cyclonedx = "cyclonedx"


class CodebaseSBOMRequest(BaseModel):
    repository: str
    branch: str | None = None
    format: Format | None = None
    include_dev: bool | None = None


class CodebaseSBOMResponse(BaseModel):
    success: bool | None = None
    sbom_id: str | None = None
    format: str | None = None


class CodebaseSecretsScanRequest(BaseModel):
    repository: str
    branch: str | None = None
    include_history: bool | None = None
    patterns: list[str] | None = None


class CodebaseSecretsScanStartResponse(BaseModel):
    success: bool | None = None
    scan_id: str | None = None
    status: str | None = None
    repository: str | None = None
    include_history: bool | None = None


class CodebaseSecretsScanResultResponse(BaseModel):
    success: bool | None = None
    scan_id: str | None = None
    findings: list[dict[str, Any]] | None = None
    total: int | None = None


class CodebaseSecretsListResponse(BaseModel):
    success: bool | None = None
    secrets: list[dict[str, Any]] | None = None
    total: int | None = None


class CodebaseSecretsScanListResponse(BaseModel):
    success: bool | None = None
    scans: list[dict[str, Any]] | None = None
    total: int | None = None
    limit: int | None = None
    offset: int | None = None


class DecisionRequest(BaseModel):
    request_id: str | None = None
    content: str
    decision_type: str | None = None
    source: str | None = None
    response_channels: list[dict[str, Any]] | None = None
    context: dict[str, Any] | None = None
    config: dict[str, Any] | None = None
    priority: str | None = None
    attachments: list[dict[str, Any]] | None = None
    evidence: list[dict[str, Any]] | None = None
    documents: list[str] | None = None


class DecisionResult(BaseModel):
    request_id: str
    decision_type: str
    answer: str
    confidence: float
    consensus_reached: bool | None = None
    reasoning: str | None = None
    evidence_used: list[dict[str, Any]] | None = None
    agent_contributions: list[dict[str, Any]] | None = None
    duration_seconds: float | None = None
    completed_at: datetime | None = None
    success: bool | None = None
    error: str | None = None


class DecisionStatus(BaseModel):
    request_id: str
    status: str
    completed_at: str | None = None


class DecisionSummary(BaseModel):
    request_id: str
    status: str | None = None
    completed_at: str | None = None


class DecisionList(BaseModel):
    decisions: list[DecisionSummary]
    total: int


class DeliberationRequest(BaseModel):
    request_id: str | None = None
    content: str
    decision_type: str | None = None
    async_: Annotated[bool | None, Field(alias="async")] = None
    priority: str | None = None
    timeout_seconds: float | None = None
    required_capabilities: list[str] | None = None
    response_channels: list[dict[str, Any]] | None = None
    metadata: dict[str, Any] | None = None


class DeliberationQueuedResponse(BaseModel):
    task_id: str
    request_id: str
    status: str


class DeliberationSyncResponse(BaseModel):
    request_id: str
    status: str
    decision_type: str | None = None
    answer: str | None = None
    confidence: float | None = None
    consensus_reached: bool | None = None
    reasoning: str | None = None
    evidence_used: list[dict[str, Any]] | None = None
    duration_seconds: float | None = None
    error: str | None = None


class DeliberationRecord(BaseModel):
    request_id: str
    status: str
    result: DecisionResult | None = None
    completed_at: datetime | None = None
    error: str | None = None
    metrics: dict[str, Any] | None = None


class DeliberationStatus(BaseModel):
    request_id: str
    status: str
    completed_at: str | None = None


class GitHubReviewComment(BaseModel):
    id: str
    file_path: str
    line: int
    body: str
    side: str | None = None
    suggestion: str | None = None
    severity: str | None = None
    category: str | None = None


class GitHubPRReviewResult(BaseModel):
    review_id: str
    pr_number: int
    repository: str
    status: str
    verdict: str | None = None
    summary: str | None = None
    comments: list[GitHubReviewComment]
    started_at: datetime
    completed_at: datetime | None = None
    error: str | None = None
    metrics: dict[str, Any] | None = None


class ChangedFile(BaseModel):
    filename: str | None = None
    status: str | None = None
    additions: int | None = None
    deletions: int | None = None
    patch: str | None = None


class GitHubPRDetails(BaseModel):
    number: int
    title: str
    body: str | None = None
    state: str
    author: str
    base_branch: str
    head_branch: str
    changed_files: list[ChangedFile] | None = None
    commits: list[dict[str, Any]] | None = None
    labels: list[str] | None = None
    created_at: datetime | None = None
    updated_at: datetime | None = None


class ReviewType(StrEnum):
    comprehensive = "comprehensive"
    quick = "quick"
    security = "security"


class GitHubPRReviewTriggerRequest(BaseModel):
    repository: Annotated[str, Field(description="owner/repo")]
    pr_number: int
    review_type: ReviewType | None = None
    workspace_id: str | None = None


class GitHubPRReviewTriggerResponse(BaseModel):
    success: bool
    review_id: str | None = None
    status: str | None = None
    pr_number: int | None = None
    repository: str | None = None
    error: str | None = None


class GitHubPRDetailsResponse(BaseModel):
    success: bool
    pr: GitHubPRDetails | None = None
    error: str | None = None


class GitHubPRReviewStatusResponse(BaseModel):
    success: bool
    review: GitHubPRReviewResult | None = None
    error: str | None = None


class GitHubPRReviewListResponse(BaseModel):
    success: bool
    reviews: list[GitHubPRReviewResult]
    total: int
    error: str | None = None


class Event(StrEnum):
    APPROVE = "APPROVE"
    REQUEST_CHANGES = "REQUEST_CHANGES"
    COMMENT = "COMMENT"


class Comment(BaseModel):
    path: str
    position: int
    body: str


class GitHubPRSubmitReviewRequest(BaseModel):
    repository: Annotated[str, Field(description="owner/repo")]
    event: Event
    body: str | None = None
    comments: list[Comment] | None = None


class GitHubPRSubmitReviewResponse(BaseModel):
    success: bool
    demo: bool | None = None
    data: dict[str, Any] | None = None
    error: str | None = None


class CostBreakdownItem(BaseModel):
    name: str | None = None
    cost: float | None = None
    percentage: float | None = None


class CostDailyItem(BaseModel):
    date: str | None = None
    cost: float | None = None
    tokens: int | None = None


class CostAlert(BaseModel):
    id: str | None = None
    type: str | None = None
    message: str | None = None
    severity: str | None = None
    timestamp: str | None = None


class CostSummaryResponse(BaseModel):
    totalCost: float | None = None
    budget: float | None = None
    tokensUsed: int | None = None
    apiCalls: int | None = None
    lastUpdated: str | None = None
    costByProvider: list[CostBreakdownItem] | None = None
    costByFeature: list[CostBreakdownItem] | None = None
    dailyCosts: list[CostDailyItem] | None = None
    alerts: list[CostAlert] | None = None


class CostBreakdownResponse(BaseModel):
    groupBy: str | None = None
    breakdown: list[CostBreakdownItem] | None = None
    total: float | None = None


class CostTimelineResponse(BaseModel):
    timeline: list[CostDailyItem] | None = None
    total: float | None = None
    average: float | None = None


class CostAlertsResponse(BaseModel):
    alerts: list[CostAlert] | None = None


class CostBudgetRequest(BaseModel):
    budget: float
    workspace_id: str | None = None


class CostBudgetResponse(BaseModel):
    success: bool
    budget: float | None = None
    workspace_id: str | None = None


class CostDismissAlertResponse(BaseModel):
    success: bool


class BudgetPeriod(StrEnum):
    daily = "daily"
    weekly = "weekly"
    monthly = "monthly"
    quarterly = "quarterly"
    annual = "annual"
    unlimited = "unlimited"


class BudgetStatus(StrEnum):
    active = "active"
    warning = "warning"
    critical = "critical"
    exceeded = "exceeded"
    suspended = "suspended"
    paused = "paused"
    closed = "closed"


class BudgetAction(StrEnum):
    notify = "notify"
    warn = "warn"
    soft_limit = "soft_limit"
    hard_limit = "hard_limit"
    suspend = "suspend"


class BudgetThreshold(BaseModel):
    percentage: Annotated[
        float, Field(description="Threshold percentage (0.0 - 1.0)", ge=0.0, le=1.0)
    ]
    action: BudgetAction


class Budget(BaseModel):
    id: str
    workspace_id: str
    name: str
    description: str | None = None
    limit_usd: float
    period: BudgetPeriod
    status: BudgetStatus
    current_spend_usd: float | None = None
    current_period_start: datetime | None = None
    current_period_end: datetime | None = None
    thresholds: list[BudgetThreshold] | None = None
    scope: dict[str, Any] | None = None
    created_at: datetime | None = None
    updated_at: datetime | None = None
    created_by: str | None = None


class BudgetCreateRequest(BaseModel):
    name: str
    description: str | None = None
    limit_usd: float
    period: BudgetPeriod
    thresholds: list[BudgetThreshold] | None = None
    scope: dict[str, Any] | None = None


class BudgetUpdateRequest(BaseModel):
    name: str | None = None
    description: str | None = None
    limit_usd: float | None = None
    period: BudgetPeriod | None = None
    status: BudgetStatus | None = None
    thresholds: list[BudgetThreshold] | None = None


class BudgetListResponse(BaseModel):
    budgets: list[Budget]
    total: int
    offset: int | None = None
    limit: int | None = None


class Trend(StrEnum):
    increasing = "increasing"
    stable = "stable"
    decreasing = "decreasing"


class BudgetSummary(BaseModel):
    total_budget_usd: float | None = None
    total_spend_usd: float | None = None
    active_budgets: int | None = None
    warning_budgets: int | None = None
    exceeded_budgets: int | None = None
    utilization_percentage: float | None = None
    trend: Trend | None = None


class BudgetCheckRequest(BaseModel):
    operation_type: str
    estimated_cost_usd: float | None = None
    model: str | None = None
    tokens: int | None = None


class BudgetCheckResponse(BaseModel):
    allowed: bool
    budget_id: str | None = None
    remaining_usd: float | None = None
    current_utilization: float | None = None
    reason: str | None = None


class BudgetAlert(BaseModel):
    id: str
    budget_id: str
    budget_name: str
    threshold_percentage: float
    actual_percentage: float | None = None
    action_taken: BudgetAction
    message: str | None = None
    created_at: datetime | None = None
    acknowledged: bool | None = None
    acknowledged_at: datetime | None = None
    acknowledged_by: str | None = None


class BudgetAlertListResponse(BaseModel):
    alerts: list[BudgetAlert]
    total: int
    unacknowledged_count: int | None = None


class BudgetOverrideRequest(BaseModel):
    budget_id: str
    override_limit_usd: float
    duration_hours: float | None = None
    reason: str


class BudgetOverrideResponse(BaseModel):
    override_added: bool
    budget_id: str
    user_id: str
    duration_hours: float | None = None


class SharedInbox(BaseModel):
    id: str | None = None
    workspace_id: str | None = None
    name: str | None = None
    description: str | None = None
    email_address: str | None = None
    connector_type: str | None = None
    team_members: list[str] | None = None
    admins: list[str] | None = None
    message_count: int | None = None
    unread_count: int | None = None
    settings: dict[str, Any] | None = None
    created_at: str | None = None
    updated_at: str | None = None
    created_by: str | None = None


class SharedInboxMessage(BaseModel):
    id: str | None = None
    inbox_id: str | None = None
    email_id: str | None = None
    subject: str | None = None
    from_address: str | None = None
    to_addresses: list[str] | None = None
    snippet: str | None = None
    received_at: str | None = None
    status: str | None = None
    assigned_to: str | None = None
    tags: list[str] | None = None
    priority: str | None = None


class SharedInboxResponse(BaseModel):
    success: bool
    inbox: SharedInbox | None = None
    error: str | None = None


class SharedInboxListResponse(BaseModel):
    success: bool
    inboxes: list[SharedInbox]
    total: int


class SharedInboxMessageListResponse(BaseModel):
    success: bool
    messages: list[SharedInboxMessage]
    total: int
    limit: int | None = None
    offset: int | None = None


class SharedInboxMessageResponse(BaseModel):
    success: bool
    message: SharedInboxMessage | None = None
    error: str | None = None


class SharedInboxCreateRequest(BaseModel):
    workspace_id: str
    name: str
    description: str | None = None
    email_address: str | None = None
    connector_type: str | None = None
    team_members: list[str] | None = None
    admins: list[str] | None = None
    settings: dict[str, Any] | None = None


class SharedInboxAssignRequest(BaseModel):
    assigned_to: str


class SharedInboxStatusRequest(BaseModel):
    status: str


class SharedInboxTagRequest(BaseModel):
    tag: str


class RoutingRule(BaseModel):
    id: str | None = None
    workspace_id: str | None = None
    name: str | None = None
    conditions: list[dict[str, Any]] | None = None
    condition_logic: str | None = None
    actions: list[dict[str, Any]] | None = None
    priority: int | None = None
    enabled: bool | None = None
    description: str | None = None
    created_at: str | None = None
    updated_at: str | None = None
    created_by: str | None = None
    stats: dict[str, Any] | None = None


class RoutingRuleResponse(BaseModel):
    success: bool
    rule: RoutingRule | None = None
    error: str | None = None


class RoutingRuleListResponse(BaseModel):
    success: bool
    rules: list[RoutingRule]
    total: int
    limit: int | None = None
    offset: int | None = None


class RoutingRuleDeleteResponse(BaseModel):
    success: bool
    deleted: str | None = None


class RoutingRuleTestResponse(BaseModel):
    success: bool
    rule_id: str | None = None
    match_count: int | None = None
    rule: RoutingRule | None = None
    error: str | None = None


class RoutingRuleCreateRequest(BaseModel):
    workspace_id: str
    name: str
    conditions: list[dict[str, Any]]
    condition_logic: str | None = None
    actions: list[dict[str, Any]]
    priority: int | None = None
    enabled: bool | None = None
    description: str | None = None


class RoutingRuleUpdateRequest(BaseModel):
    name: str | None = None
    description: str | None = None
    conditions: list[dict[str, Any]] | None = None
    condition_logic: str | None = None
    actions: list[dict[str, Any]] | None = None
    priority: int | None = None
    enabled: bool | None = None


class RoutingRuleTestRequest(BaseModel):
    workspace_id: str


class ByTier(BaseModel):
    fast: int | None = None
    medium: int | None = None
    slow: int | None = None
    glacial: int | None = None


class MemoryStats(BaseModel):
    total_entries: int | None = None
    by_tier: ByTier | None = None
    cache_hit_rate: float | None = None


class Tier(StrEnum):
    fast = "fast"
    medium = "medium"
    slow = "slow"
    glacial = "glacial"


class MemoryEntry(BaseModel):
    id: Annotated[str, Field(description="Unique memory ID")]
    content: Annotated[str, Field(description="Memory content")]
    tier: Annotated[Tier, Field(description="Memory tier")]
    created_at: datetime | None = None
    expires_at: datetime | None = None
    relevance_score: Annotated[float | None, Field(description="Relevance to query 0-1")] = None
    metadata: dict[str, Any] | None = None


class MemoryRetrievalResponse(BaseModel):
    memories: list[MemoryEntry] | None = None
    total: int | None = None
    tier: str | None = None
    query: str | None = None


class MemoryTierStats(BaseModel):
    tier: Tier | None = None
    count: int | None = None
    size_bytes: int | None = None
    oldest_entry: datetime | None = None
    newest_entry: datetime | None = None
    avg_age_seconds: float | None = None


class MemoryTierStatsResponse(BaseModel):
    tiers: list[MemoryTierStats] | None = None
    total_memories: int | None = None
    total_size_bytes: int | None = None


class MemoryArchiveStats(BaseModel):
    archived_count: int | None = None
    archive_size_bytes: int | None = None
    oldest_archive: datetime | None = None
    compression_ratio: float | None = None


class MemoryConsolidationResult(BaseModel):
    memories_processed: int | None = None
    memories_promoted: int | None = None
    memories_demoted: int | None = None
    duration_ms: int | None = None


class MemoryCleanupResult(BaseModel):
    memories_removed: int | None = None
    bytes_freed: int | None = None
    duration_ms: int | None = None


class KnowledgeNode(BaseModel):
    id: Annotated[str, Field(description="Unique node ID")]
    content: Annotated[str, Field(description="Node content")]
    source: Annotated[str | None, Field(description="Knowledge source type")] = None
    confidence: Annotated[float | None, Field(description="Confidence score 0-1")] = None
    created_at: datetime | None = None
    updated_at: datetime | None = None
    topics: list[str] | None = None
    metadata: dict[str, Any] | None = None


class KnowledgeQueryResult(BaseModel):
    items: list[KnowledgeNode] | None = None
    total: int | None = None
    query: str | None = None
    relevance_scores: list[float] | None = None


class KnowledgeStoreResult(BaseModel):
    id: str | None = None
    success: bool | None = None
    source: str | None = None
    timestamp: datetime | None = None


class KnowledgeFact(BaseModel):
    id: str | None = None
    content: str | None = None
    source: str | None = None
    confidence: float | None = None
    evidence: list[str] | None = None
    contradictions: list[str] | None = None
    created_at: datetime | None = None
    verified_at: datetime | None = None


class KnowledgeFactList(BaseModel):
    facts: list[KnowledgeFact] | None = None
    total: int | None = None


class KnowledgeSearchResult(BaseModel):
    node: KnowledgeNode | None = None
    score: float | None = None
    highlights: list[str] | None = None


class KnowledgeSearchResponse(BaseModel):
    results: list[KnowledgeSearchResult] | None = None
    total: int | None = None
    query: str | None = None
    search_time_ms: int | None = None


class KnowledgeStats(BaseModel):
    total_nodes: int | None = None
    total_facts: int | None = None
    by_source: dict[str, int] | None = None
    avg_confidence: float | None = None
    contradiction_rate: float | None = None


class KnowledgeQueryResponse(BaseModel):
    success: bool | None = None
    result: KnowledgeQueryResult | None = None


class DisagreementStats(BaseModel):
    total_debates: Annotated[int | None, Field(description="Total debates analyzed")] = None
    with_disagreements: Annotated[int | None, Field(description="Debates with disagreements")] = (
        None
    )
    unanimous: Annotated[int | None, Field(description="Unanimous debates")] = None
    disagreement_types: Annotated[
        dict[str, int] | None, Field(description="Count by disagreement type")
    ] = None


class ByAgent(BaseModel):
    proposer: int | None = None
    critic: int | None = None
    judge: int | None = None


class RoleRotationStats(BaseModel):
    total_rotations: int | None = None
    by_agent: dict[str, ByAgent] | None = None


class EarlyStopStats(BaseModel):
    total_early_stops: int | None = None
    by_reason: dict[str, int] | None = None
    average_rounds_saved: float | None = None


class RankingStats(BaseModel):
    total_agents: int | None = None
    average_elo: float | None = None
    highest_elo: float | None = None
    lowest_elo: float | None = None
    total_matches: int | None = None


class PositionFlip(BaseModel):
    debate_id: str | None = None
    agent: str | None = None
    round: int | None = None
    old_position: str | None = None
    new_position: str | None = None
    reason: str | None = None
    conviction_delta: float | None = None
    timestamp: datetime | None = None


class FlipsRecent(BaseModel):
    flips: list[PositionFlip] | None = None
    total: int | None = None


class FlipsSummary(BaseModel):
    total_flips: int | None = None
    by_agent: dict[str, int] | None = None
    by_debate: dict[str, int] | None = None
    average_conviction_delta: float | None = None
    flip_rate: Annotated[float | None, Field(description="Percentage of debates with flips")] = None


class Type1(StrEnum):
    observation = "observation"
    conclusion = "conclusion"
    recommendation = "recommendation"


class Insight(BaseModel):
    id: str | None = None
    debate_id: str | None = None
    content: str | None = None
    type: Type1 | None = None
    confidence: float | None = None
    supporting_evidence: list[str] | None = None
    extracted_at: datetime | None = None


class InsightsRecent(BaseModel):
    insights: list[Insight] | None = None
    total: int | None = None


class InsightsDetailed(BaseModel):
    insights: list[Insight] | None = None
    themes: list[str] | None = None
    key_findings: list[str] | None = None
    processing_time_ms: int | None = None


class Type2(StrEnum):
    breakthrough = "breakthrough"
    conflict = "conflict"
    consensus = "consensus"
    insight = "insight"
    flip = "flip"


class DebateMoment(BaseModel):
    id: str | None = None
    debate_id: str | None = None
    type: Type2 | None = None
    round: int | None = None
    description: str | None = None
    participants: list[str] | None = None
    significance_score: float | None = None
    timestamp: datetime | None = None


class TopDebate(BaseModel):
    debate_id: str | None = None
    moment_count: int | None = None


class MomentsSummary(BaseModel):
    total_moments: int | None = None
    by_type: dict[str, int] | None = None
    top_debates: list[TopDebate] | None = None


class MomentsTimeline(BaseModel):
    moments: list[DebateMoment] | None = None
    start_time: datetime | None = None
    end_time: datetime | None = None


class MomentsTrending(BaseModel):
    moments: list[DebateMoment] | None = None
    trending_period_hours: int | None = None


class MomentsByType(BaseModel):
    type: str | None = None
    moments: list[DebateMoment] | None = None
    total: int | None = None


class Platform(StrEnum):
    google_ads = "google_ads"
    meta_ads = "meta_ads"
    linkedin_ads = "linkedin_ads"
    microsoft_ads = "microsoft_ads"


class Status2(StrEnum):
    ENABLED = "ENABLED"
    PAUSED = "PAUSED"
    REMOVED = "REMOVED"


class UnifiedCampaign(BaseModel):
    id: Annotated[str, Field(description="Platform-specific campaign ID")]
    platform: Annotated[Platform, Field(description="Advertising platform name")]
    name: Annotated[str, Field(description="Campaign name")]
    status: Annotated[Status2, Field(description="Campaign status")]
    objective: Annotated[str | None, Field(description="Campaign objective/goal")] = None
    daily_budget: Annotated[float | None, Field(description="Daily budget in account currency")] = (
        None
    )
    total_budget: Annotated[float | None, Field(description="Total campaign budget")] = None
    start_date: Annotated[date_aliased | None, Field(description="Campaign start date")] = None
    end_date: Annotated[date_aliased | None, Field(description="Campaign end date")] = None
    created_at: Annotated[datetime | None, Field(description="When the campaign was created")] = (
        None
    )
    updated_at: Annotated[
        datetime | None, Field(description="When the campaign was last updated")
    ] = None


class AnalyticsDebatesOverview(BaseModel):
    time_range: str | None = None
    total_debates: int | None = None
    debates_this_period: int | None = None
    debates_previous_period: int | None = None
    growth_rate: float | None = None
    consensus_reached: int | None = None
    consensus_rate: float | None = None
    avg_rounds: float | None = None
    avg_agents_per_debate: float | None = None
    avg_confidence: float | None = None
    generated_at: datetime | None = None


class AnalyticsDebateTrendPoint(BaseModel):
    period: str | None = None
    total: int | None = None
    consensus_reached: int | None = None
    consensus_rate: float | None = None
    avg_rounds: float | None = None


class AnalyticsDebatesTrends(BaseModel):
    time_range: str | None = None
    granularity: str | None = None
    data_points: list[AnalyticsDebateTrendPoint] | None = None
    generated_at: datetime | None = None


class AnalyticsDebateTopic(BaseModel):
    topic: str | None = None
    count: int | None = None
    percentage: float | None = None
    consensus_rate: float | None = None


class AnalyticsDebatesTopics(BaseModel):
    time_range: str | None = None
    topics: list[AnalyticsDebateTopic] | None = None
    total_debates: int | None = None
    generated_at: datetime | None = None


class AnalyticsOutcomeConfidenceBucket(BaseModel):
    count: int | None = None
    consensus_rate: float | None = None


class Outcomes(BaseModel):
    class Config:
        extra = Extra.forbid

    consensus: int | None = None
    majority: int | None = None
    dissent: int | None = None
    no_resolution: int | None = None


class AnalyticsDebatesOutcomes(BaseModel):
    time_range: str | None = None
    outcomes: Outcomes | None = None
    total_debates: int | None = None
    by_confidence: dict[str, AnalyticsOutcomeConfidenceBucket] | None = None
    generated_at: datetime | None = None


class AnalyticsLeaderboardEntry(BaseModel):
    rank: int | None = None
    agent_name: str | None = None
    elo: float | None = None
    wins: int | None = None
    losses: int | None = None
    draws: int | None = None
    win_rate: float | None = None
    games_played: int | None = None
    calibration_score: float | None = None


class AnalyticsAgentsLeaderboard(BaseModel):
    leaderboard: list[AnalyticsLeaderboardEntry] | None = None
    total_agents: int | None = None
    domain: str | None = None
    generated_at: datetime | None = None


class AnalyticsDomainPerformanceEntry(BaseModel):
    elo: float | None = None
    wins: int | None = None
    losses: int | None = None


class AnalyticsEloHistoryPoint(BaseModel):
    timestamp: str | None = None
    elo: float | None = None


class AnalyticsAgentPerformance(BaseModel):
    agent_id: str | None = None
    agent_name: str | None = None
    time_range: str | None = None
    elo: float | None = None
    elo_change: float | None = None
    rank: int | None = None
    wins: int | None = None
    losses: int | None = None
    draws: int | None = None
    win_rate: float | None = None
    games_played: int | None = None
    debates_count: int | None = None
    consensus_contribution_rate: float | None = None
    calibration_score: float | None = None
    calibration_accuracy: float | None = None
    domain_performance: dict[str, AnalyticsDomainPerformanceEntry] | None = None
    recent_matches: list[dict[str, Any]] | None = None
    elo_history: list[AnalyticsEloHistoryPoint] | None = None
    generated_at: datetime | None = None


class AnalyticsAgentComparisonEntry(BaseModel):
    agent_name: str | None = None
    elo: float | None = None
    wins: int | None = None
    losses: int | None = None
    draws: int | None = None
    win_rate: float | None = None
    games_played: int | None = None
    calibration_score: float | None = None
    error: str | None = None


class AnalyticsAgentsComparison(BaseModel):
    agents: list[str] | None = None
    comparison: list[AnalyticsAgentComparisonEntry] | None = None
    head_to_head: dict[str, dict[str, Any]] | None = None
    generated_at: datetime | None = None


class AnalyticsAgentTrendPoint(BaseModel):
    period: str | None = None
    elo: float | None = None
    games: int | None = None


class AnalyticsAgentsTrends(BaseModel):
    agents: list[str] | None = None
    time_range: str | None = None
    granularity: str | None = None
    trends: dict[str, list[AnalyticsAgentTrendPoint]] | None = None
    generated_at: datetime | None = None


class AnalyticsTokenSummary(BaseModel):
    total_tokens_in: float | None = None
    total_tokens_out: float | None = None
    total_tokens: float | None = None
    avg_tokens_per_day: float | None = None


class Trend1(BaseModel):
    period: str | None = None
    tokens_in: float | None = None
    tokens_out: float | None = None


class AnalyticsUsageTokens(BaseModel):
    org_id: str | None = None
    time_range: str | None = None
    granularity: str | None = None
    summary: AnalyticsTokenSummary | None = None
    trends: list[Trend1] | None = None
    by_agent: dict[str, float] | None = None
    by_model: dict[str, float] | None = None
    message: str | None = None
    generated_at: datetime | None = None


class AnalyticsCostSummary(BaseModel):
    total_cost_usd: str | None = None
    avg_cost_per_day: str | None = None
    avg_cost_per_debate: str | None = None
    total_api_calls: int | None = None


class ByProvider(BaseModel):
    cost: str | None = None
    percentage: float | None = None


class AnalyticsUsageCosts(BaseModel):
    org_id: str | None = None
    time_range: str | None = None
    summary: AnalyticsCostSummary | None = None
    by_provider: dict[str, ByProvider] | None = None
    by_model: dict[str, dict[str, Any]] | None = None
    message: str | None = None
    generated_at: datetime | None = None


class AnalyticsActiveUserCounts(BaseModel):
    daily: int | None = None
    weekly: int | None = None
    monthly: int | None = None


class AnalyticsUserGrowth(BaseModel):
    new_users: int | None = None
    churned_users: int | None = None
    net_growth: int | None = None


class AnalyticsActivityDistribution(BaseModel):
    power_users: int | None = None
    regular_users: int | None = None
    occasional_users: int | None = None


class AnalyticsActiveUsers(BaseModel):
    org_id: str | None = None
    time_range: str | None = None
    active_users: AnalyticsActiveUserCounts | None = None
    user_growth: AnalyticsUserGrowth | None = None
    activity_distribution: AnalyticsActivityDistribution | None = None
    message: str | None = None
    generated_at: datetime | None = None


class Role1(StrEnum):
    observer = "observer"
    participant = "participant"
    moderator = "moderator"


class DebateJoinRequest(BaseModel):
    role: Annotated[Role1 | None, Field(description="Role in the debate")] = "observer"
    display_name: Annotated[
        str | None,
        Field(description="Display name shown to other participants", max_length=100),
    ] = None


class DebateVoteRequest(BaseModel):
    position: Annotated[
        str,
        Field(description="The position being voted on", max_length=500, min_length=1),
    ]
    intensity: Annotated[
        int | None,
        Field(description="Vote intensity/conviction (1=weak, 10=strong)", ge=1, le=10),
    ] = 5
    reasoning: Annotated[
        str | None,
        Field(description="Optional reasoning for the vote", max_length=2000),
    ] = None


class Type3(StrEnum):
    argument = "argument"
    question = "question"
    evidence = "evidence"
    follow_up = "follow_up"


class DebateSuggestionRequest(BaseModel):
    content: Annotated[
        str,
        Field(description="The suggestion or argument text", max_length=5000, min_length=1),
    ]
    type: Annotated[Type3 | None, Field(description="Type of suggestion")] = "argument"
    target_agent: Annotated[
        str | None,
        Field(description="Optional: direct the suggestion at a specific agent"),
    ] = None


class Consensus2(StrEnum):
    majority = "majority"
    unanimous = "unanimous"
    supermajority = "supermajority"
    weighted = "weighted"
    hybrid = "hybrid"
    judge = "judge"
    none = "none"


class DebateUpdateRequest(BaseModel):
    rounds: Annotated[int | None, Field(description="Update max rounds", ge=1, le=12)] = None
    consensus: Annotated[Consensus2 | None, Field(description="Change consensus strategy")] = None
    context: Annotated[
        str | None, Field(description="Append additional context", max_length=10000)
    ] = None
    metadata: Annotated[
        dict[str, Any] | None,
        Field(description="Update metadata (merged with existing)"),
    ] = None


class DebateForkRequest(BaseModel):
    branch_point: Annotated[int, Field(description="Round number to branch from (1-indexed)", ge=1)]
    new_premise: Annotated[
        str | None,
        Field(description="New premise or constraint for the forked branch", max_length=2000),
    ] = None


class Format1(StrEnum):
    audio = "audio"
    video = "video"


class DebateBroadcastRequest(BaseModel):
    format: Annotated[Format1 | None, Field(description="Output format for the broadcast")] = (
        "audio"
    )
    voices: Annotated[
        dict[str, str] | None,
        Field(description="Voice mapping (agent_name -> voice_id)"),
    ] = None
    language: Annotated[str | None, Field(description="Language code for TTS")] = "en-US"


class DebateCloneRequest(BaseModel):
    preserveAgents: Annotated[bool | None, Field(description="Keep the same agent lineup")] = True
    preserveContext: Annotated[
        bool | None, Field(description="Keep the original context and documents")
    ] = True


class DebateFollowupRequest(BaseModel):
    cruxId: Annotated[str | None, Field(description="ID of the crux claim to follow up on")] = None
    context: Annotated[
        str | None,
        Field(description="Additional context for the follow-up", max_length=5000),
    ] = None


class DebateEvidenceRequest(BaseModel):
    evidence: Annotated[
        str,
        Field(description="The evidence text or URL", max_length=10000, min_length=1),
    ]
    source: Annotated[str | None, Field(description="Source attribution", max_length=500)] = None
    metadata: Annotated[
        dict[str, Any] | None,
        Field(description="Additional metadata about the evidence"),
    ] = None


class DebateVerifyClaimRequest(BaseModel):
    claim_id: Annotated[str, Field(description="ID of the claim to verify")]
    evidence: Annotated[
        str | None,
        Field(description="Optional evidence to check the claim against", max_length=5000),
    ] = None


class Type4(StrEnum):
    suggestion = "suggestion"
    vote = "vote"
    question = "question"
    context = "context"


class DebateUserInputRequest(BaseModel):
    input: Annotated[str, Field(description="The user's input text", max_length=5000, min_length=1)]
    type: Annotated[Type4 | None, Field(description="Type of user input")] = "suggestion"


class DebateCounterfactualRequest(BaseModel):
    condition: Annotated[
        str, Field(description="The hypothetical condition to analyze", max_length=2000)
    ]
    variables: Annotated[
        dict[str, Any] | None, Field(description="Variables to adjust in the scenario")
    ] = None


class Role2(StrEnum):
    user = "user"
    system = "system"


class DebateMessageRequest(BaseModel):
    content: Annotated[str, Field(description="Message content", max_length=5000, min_length=1)]
    role: Annotated[Role2 | None, Field(description="Message role")] = "user"


class DebateBatchRequest(BaseModel):
    requests: Annotated[
        list[DebateCreateRequest],
        Field(description="Array of debate creation requests", max_items=50, min_items=1),
    ]


class Type5(StrEnum):
    argument = "argument"
    follow_up = "follow_up"


class DebateInjectArgumentRequest(BaseModel):
    content: Annotated[
        str,
        Field(description="The argument or question to inject", max_length=5000, min_length=1),
    ]
    type: Annotated[Type5 | None, Field(description="Type of injection")] = "argument"
    source: Annotated[str | None, Field(description="Source identifier")] = "user"
    user_id: Annotated[str | None, Field(description="User ID for attribution")] = None


class DebateUpdateWeightsRequest(BaseModel):
    agent: Annotated[str, Field(description="Agent name or ID", min_length=1)]
    weight: Annotated[
        float,
        Field(description="Influence weight (0.0=muted, 1.0=normal, 2.0=double)", ge=0.0, le=2.0),
    ]
    user_id: Annotated[str | None, Field(description="User ID for audit trail")] = None


class DebateUpdateThresholdRequest(BaseModel):
    threshold: Annotated[
        float,
        Field(
            description="Consensus threshold (0.5=majority, 0.75=strong, 1.0=unanimous)",
            ge=0.5,
            le=1.0,
        ),
    ]
    user_id: Annotated[str | None, Field(description="User ID for audit trail")] = None


class DebateCostEstimateRequest(BaseModel):
    num_agents: Annotated[
        int | None, Field(description="Number of agents to participate", ge=1, le=8)
    ] = 3
    num_rounds: Annotated[int | None, Field(description="Number of debate rounds", ge=1, le=12)] = 9
    model_types: Annotated[
        list[str] | None,
        Field(
            description="Model types to use", example=["claude-sonnet-4", "gpt-4o", "gemini-pro"]
        ),
    ] = None


class BreakdownByModelItem(BaseModel):
    model: str | None = None
    provider: str | None = None
    estimated_input_tokens: int | None = None
    estimated_output_tokens: int | None = None
    input_cost_usd: float | None = None
    output_cost_usd: float | None = None
    subtotal_usd: float | None = None


class Assumptions(BaseModel):
    avg_input_tokens_per_round: int | None = None
    avg_output_tokens_per_round: int | None = None
    includes_system_prompt: bool | None = None


class DebateCostEstimateResponse(BaseModel):
    total_estimated_cost_usd: Annotated[float, Field(description="Total estimated cost in USD")]
    breakdown_by_model: Annotated[
        list[BreakdownByModelItem], Field(description="Cost breakdown per model")
    ]
    assumptions: Annotated[
        Assumptions | None, Field(description="Assumptions used for the estimate")
    ] = None
    num_agents: int | None = None
    num_rounds: int | None = None


class WebSocketResumeToken(BaseModel):
    resume_token: Annotated[
        str, Field(description="Opaque token encoding the last received event position")
    ]
    debate_id: Annotated[str, Field(description="Debate this token belongs to")]
    last_seq: Annotated[int, Field(description="Sequence number of last received event")]
    expires_at: Annotated[datetime | None, Field(description="When this resume token expires")] = (
        None
    )


class Debate(BaseModel):
    debate_id: str | None = None
    id: str | None = None
    slug: str | None = None
    task: str | None = None
    topic: Annotated[str | None, Field(description="Alias for task")] = None
    context: str | None = None
    status: DebateStatus | None = None
    outcome: str | None = None
    final_answer: str | None = None
    consensus: ConsensusResult | None = None
    consensus_proof: dict[str, Any] | None = None
    consensus_reached: bool | None = None
    confidence: float | None = None
    rounds_used: int | None = None
    duration_seconds: float | None = None
    agents: list[str] | None = None
    rounds: list[Round] | None = None
    created_at: datetime | None = None
    completed_at: datetime | None = None
    metadata: dict[str, Any] | None = None
