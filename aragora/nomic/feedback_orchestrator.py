"""Unified Feedback Orchestrator for Self-Improvement.

Bridges 6 audit subsystems into active feedback that informs the next
self-improvement cycle.  Runs as Step 7 of ``SelfImprovePipeline.run()``,
after execution and before cycle end.

Steps:
1. Gauntlet: validate execution receipts
2. Introspection: capture agent performance snapshots
3. Genesis: auto-breed improved agent configs when quality < threshold
4. Learning: adjust hyperparameters from cycle outcomes
5. Workspace: deduplicate work via bead fingerprints
6. Pulse: inject trending topics into improvement queue
7. Knowledge Contradiction: detect conflicting knowledge in KnowledgeMound

Results are persisted to the ImprovementQueue (SQLite-backed) which
MetaPlanner._scan_prioritize() reads as Signal 8/10 on the next cycle.

Usage:
    orchestrator = SelfImproveFeedbackOrchestrator()
    report = orchestrator.run(cycle_id, execution_results)
"""

from __future__ import annotations

import json
import logging
import sqlite3
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)

# Default path for the legacy JSON improvement queue
_DEFAULT_QUEUE_PATH = Path(".aragora_beads") / "improvement_queue.json"


# ---------------------------------------------------------------------------
# Dataclasses
# ---------------------------------------------------------------------------


@dataclass
class ImprovementGoal:
    """A single improvement goal produced by the feedback orchestrator."""

    goal: str
    source: str  # e.g., "gauntlet_finding", "introspection_gap", "pulse_trending"
    priority: float  # 0.0-1.0
    context: dict[str, Any] = field(default_factory=dict)


@dataclass
class FeedbackReport:
    """Full report returned by ``SelfImproveFeedbackOrchestrator.run()``.

    Contains rich subsystem outputs alongside backward-compatible integer
    counters that existing consumers (self_improve.py, tests) rely on.
    """

    cycle_id: str

    # Rich subsystem outputs
    gauntlet_findings: list[dict[str, Any]] = field(default_factory=list)
    introspection_snapshot: dict[str, Any] = field(default_factory=dict)
    genesis_recommendations: list[dict[str, Any]] = field(default_factory=list)
    learning_adjustments: dict[str, Any] = field(default_factory=dict)
    workspace_dedup_results: dict[str, Any] = field(default_factory=dict)
    pulse_priorities: list[dict[str, Any]] = field(default_factory=list)
    improvement_goals: list[dict[str, Any]] = field(default_factory=list)
    errors: list[str] = field(default_factory=list)

    # Backward-compatible integer counters
    goals_generated: int = 0
    steps_completed: int = 0
    steps_failed: int = 0
    introspection_snapshots: int = 0
    genesis_breeds: int = 0
    workspace_deduped: int = 0
    pulse_injections: int = 0
    contradiction_detections: int = 0


@dataclass
class FeedbackResult:
    """Legacy result dataclass for backward compatibility.

    Tests and consumers that import ``FeedbackResult`` directly with
    keyword arguments (e.g., ``FeedbackResult(cycle_id="x",
    contradiction_detections=5)``) rely on this class.
    """

    cycle_id: str
    goals_generated: int = 0
    steps_completed: int = 0
    steps_failed: int = 0
    gauntlet_findings: int = 0
    introspection_snapshots: int = 0
    genesis_breeds: int = 0
    learning_adjustments: int = 0
    workspace_deduped: int = 0
    pulse_injections: int = 0
    contradiction_detections: int = 0


@dataclass
class FeedbackGoal:
    """A goal generated by the feedback orchestrator.

    Kept for backward compatibility with existing consumers
    (hardened_orchestrator, gauntlet runner, tests).
    """

    description: str
    source: str  # e.g., "gauntlet_finding", "introspection_gap", "pulse_trending"
    track: str = "core"
    priority: int = 5
    estimated_impact: str = "medium"
    created_at: float = field(default_factory=time.time)
    metadata: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        return {
            "description": self.description,
            "source": self.source,
            "track": self.track,
            "priority": self.priority,
            "estimated_impact": self.estimated_impact,
            "created_at": self.created_at,
            "metadata": self.metadata,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> FeedbackGoal:
        return cls(
            description=data.get("description", ""),
            source=data.get("source", "unknown"),
            track=data.get("track", "core"),
            priority=data.get("priority", 5),
            estimated_impact=data.get("estimated_impact", "medium"),
            created_at=data.get("created_at", 0.0),
            metadata=data.get("metadata", {}),
        )

    def to_improvement_goal(self) -> ImprovementGoal:
        """Convert to an ImprovementGoal for the SQLite queue."""
        # Map integer priority (1=highest) to float (1.0=highest)
        float_priority = max(0.0, min(1.0, 1.0 - (self.priority - 1) * 0.2))
        return ImprovementGoal(
            goal=self.description,
            source=self.source,
            priority=float_priority,
            context={
                "track": self.track,
                "estimated_impact": self.estimated_impact,
                **self.metadata,
            },
        )


# ---------------------------------------------------------------------------
# SQLite-backed ImprovementQueue
# ---------------------------------------------------------------------------


def _resolve_queue_db_path(db_path: Path | None = None) -> str:
    """Resolve the database path for the improvement queue.

    Uses the ``resolve_db_path`` pattern from the persistence layer when
    available, otherwise falls back to ARAGORA_DATA_DIR or ~/.aragora.
    """
    if db_path is not None:
        return str(db_path)

    try:
        from aragora.persistence.db_config import resolve_db_path

        return resolve_db_path("improvement_queue.db")
    except ImportError:
        pass

    import os

    data_dir = os.environ.get("ARAGORA_DATA_DIR", str(Path.home() / ".aragora"))
    return os.path.join(data_dir, "improvement_queue.db")


class ImprovementQueue:
    """SQLite-backed queue for feedback-generated improvement goals.

    Provides both the new ``push``/``pop``/``peek`` interface for
    ``ImprovementGoal`` objects *and* the legacy ``add``/``save``/``load``
    interface with ``FeedbackGoal`` for backward compatibility.

    Table schema::

        improvement_queue(
            id          INTEGER PRIMARY KEY AUTOINCREMENT,
            goal        TEXT NOT NULL,
            source      TEXT NOT NULL,
            priority    REAL NOT NULL DEFAULT 0.5,
            context_json TEXT NOT NULL DEFAULT '{}',
            created_at  REAL NOT NULL,
            consumed    INTEGER NOT NULL DEFAULT 0
        )
    """

    _CREATE_TABLE = """\
CREATE TABLE IF NOT EXISTS improvement_queue (
    id           INTEGER PRIMARY KEY AUTOINCREMENT,
    goal         TEXT    NOT NULL,
    source       TEXT    NOT NULL,
    priority     REAL    NOT NULL DEFAULT 0.5,
    context_json TEXT    NOT NULL DEFAULT '{}',
    created_at   REAL    NOT NULL,
    consumed     INTEGER NOT NULL DEFAULT 0
)
"""

    def __init__(self, db_path: Path | None = None):
        self._db_path = _resolve_queue_db_path(db_path)
        Path(self._db_path).parent.mkdir(parents=True, exist_ok=True)
        self._ensure_table()

        # Legacy in-memory goal list (for backward-compatible .goals / .add / .save / .load)
        self.goals: list[FeedbackGoal] = []
        self.max_goals: int = 50

    def _connect(self) -> sqlite3.Connection:
        conn = sqlite3.connect(self._db_path, timeout=10)
        conn.execute("PRAGMA journal_mode=WAL")
        return conn

    def _ensure_table(self) -> None:
        conn = self._connect()
        try:
            conn.execute(self._CREATE_TABLE)
            conn.commit()
        finally:
            conn.close()

    # --- New SQLite-backed interface ---

    def push(self, goal: ImprovementGoal) -> None:
        """Push an improvement goal onto the SQLite queue."""
        conn = self._connect()
        try:
            conn.execute(
                "INSERT INTO improvement_queue (goal, source, priority, context_json, created_at, consumed) "
                "VALUES (?, ?, ?, ?, ?, 0)",
                (
                    goal.goal,
                    goal.source,
                    goal.priority,
                    json.dumps(goal.context),
                    time.time(),
                ),
            )
            conn.commit()
        finally:
            conn.close()

    def pop(self, limit: int = 10) -> list[ImprovementGoal]:
        """Pop up to *limit* unconsumed goals, marking them consumed.

        Goals are returned in priority-descending order (highest first).
        """
        conn = self._connect()
        try:
            cursor = conn.execute(
                "SELECT id, goal, source, priority, context_json "
                "FROM improvement_queue WHERE consumed = 0 "
                "ORDER BY priority DESC, id ASC LIMIT ?",
                (limit,),
            )
            rows = cursor.fetchall()
            if not rows:
                return []

            ids = [row[0] for row in rows]
            placeholders = ",".join("?" for _ in ids)
            conn.execute(
                f"UPDATE improvement_queue SET consumed = 1 WHERE id IN ({placeholders})",
                ids,
            )
            conn.commit()

            return [
                ImprovementGoal(
                    goal=row[1],
                    source=row[2],
                    priority=row[3],
                    context=json.loads(row[4]) if row[4] else {},
                )
                for row in rows
            ]
        finally:
            conn.close()

    def peek(self, limit: int = 10) -> list[ImprovementGoal]:
        """Return up to *limit* unconsumed goals without consuming them."""
        conn = self._connect()
        try:
            cursor = conn.execute(
                "SELECT goal, source, priority, context_json "
                "FROM improvement_queue WHERE consumed = 0 "
                "ORDER BY priority DESC, id ASC LIMIT ?",
                (limit,),
            )
            return [
                ImprovementGoal(
                    goal=row[0],
                    source=row[1],
                    priority=row[2],
                    context=json.loads(row[3]) if row[3] else {},
                )
                for row in cursor.fetchall()
            ]
        finally:
            conn.close()

    # --- Legacy backward-compatible interface ---

    def add(self, goal: FeedbackGoal) -> None:
        """Add a FeedbackGoal (legacy). Also pushes to SQLite."""
        self.goals.append(goal)
        if len(self.goals) > self.max_goals:
            self.goals = self.goals[-self.max_goals :]

        # Mirror into the SQLite store
        try:
            self.push(goal.to_improvement_goal())
        except (sqlite3.Error, OSError) as exc:
            logger.debug("SQLite push failed in legacy add: %s", exc)

    def save(self, path: Path | None = None) -> None:
        """Persist the in-memory goal list to JSON (legacy)."""
        target = path or _DEFAULT_QUEUE_PATH
        target.parent.mkdir(parents=True, exist_ok=True)
        data = [g.to_dict() for g in self.goals]
        target.write_text(json.dumps(data, indent=2), encoding="utf-8")

    @classmethod
    def load(cls, path: Path | None = None) -> ImprovementQueue:
        """Load in-memory goals from JSON (legacy), returning a new queue."""
        target = path or _DEFAULT_QUEUE_PATH
        queue = cls()
        if target.exists():
            try:
                data = json.loads(target.read_text(encoding="utf-8"))
                queue.goals = [FeedbackGoal.from_dict(g) for g in data]
            except (json.JSONDecodeError, KeyError, TypeError) as e:
                logger.warning("Failed to load improvement queue: %s", e)
        return queue


# ---------------------------------------------------------------------------
# Orchestrator
# ---------------------------------------------------------------------------


class SelfImproveFeedbackOrchestrator:
    """7-step feedback pipeline bridging audit subsystems to active improvement.

    Each step is wrapped in try/except for graceful degradation -- any
    subsystem failure logs a warning but does not block the pipeline.
    """

    def __init__(
        self,
        workspace_root: Path = Path.cwd(),
        *,
        queue_path: Path | None = None,
    ):
        self.workspace_root = workspace_root
        self.logger = logging.getLogger(__name__)
        self._queue_path = queue_path
        self._queue = ImprovementQueue.load(queue_path)

    def run(
        self,
        cycle_id: str,
        execution_results: list[dict[str, Any]],
    ) -> FeedbackReport:
        """Run the 7-step feedback pipeline.

        Args:
            cycle_id: The self-improvement cycle ID.
            execution_results: List of per-subtask execution result dicts.

        Returns:
            FeedbackReport with subsystem outputs and synthesised goals.
        """
        report = FeedbackReport(cycle_id=cycle_id)

        # Step 1: Gauntlet -- validate execution receipts
        try:
            goals = self._step_gauntlet(execution_results)
            report.gauntlet_findings = [g.to_dict() for g in goals]
            for g in goals:
                self._queue.add(g)
                report.goals_generated += 1
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_gauntlet_failed: %s", exc)
            report.errors.append("gauntlet")
            report.steps_failed += 1

        # Step 2: Introspection -- capture agent performance snapshots
        try:
            goals = self._step_introspection(execution_results)
            report.introspection_snapshot = {
                "gaps": [g.to_dict() for g in goals],
            }
            report.introspection_snapshots = len(goals)
            for g in goals:
                self._queue.add(g)
                report.goals_generated += 1
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_introspection_failed: %s", exc)
            report.errors.append("introspection")
            report.steps_failed += 1

        # Step 3: Genesis -- auto-breed new agent configs when quality < threshold
        try:
            breeds = self._step_genesis(execution_results)
            report.genesis_breeds = breeds
            if breeds > 0:
                report.genesis_recommendations.append({"action": "breed", "new_genomes": breeds})
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_genesis_failed: %s", exc)
            report.errors.append("genesis")
            report.steps_failed += 1

        # Step 4: Learning -- hyperparameter adjustments from cycle outcomes
        try:
            adjustments = self._step_learning(cycle_id, execution_results)
            report.learning_adjustments = {"adjustment_count": adjustments}
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_learning_failed: %s", exc)
            report.errors.append("learning")
            report.steps_failed += 1

        # Step 5: Workspace -- deduplicate via bead fingerprints
        try:
            deduped = self._step_workspace(execution_results)
            report.workspace_dedup_results = {"duplicates_found": deduped}
            report.workspace_deduped = deduped
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_workspace_failed: %s", exc)
            report.errors.append("workspace")
            report.steps_failed += 1

        # Step 6: Pulse -- inject trending topics as priorities
        try:
            goals = self._step_pulse()
            report.pulse_priorities = [g.to_dict() for g in goals]
            report.pulse_injections = len(goals)
            for g in goals:
                self._queue.add(g)
                report.goals_generated += 1
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_pulse_failed: %s", exc)
            report.errors.append("pulse")
            report.steps_failed += 1

        # Step 7: Knowledge Contradiction -- detect conflicting knowledge in KM
        try:
            goals = self._step_knowledge_contradiction(cycle_id)
            report.contradiction_detections = len(goals)
            for g in goals:
                self._queue.add(g)
                report.goals_generated += 1
            report.steps_completed += 1
        except (
            ImportError,
            RuntimeError,
            ValueError,
            TypeError,
            OSError,
            AttributeError,
            KeyError,
        ) as exc:
            logger.warning("feedback_step_knowledge_contradiction_failed: %s", exc)
            report.errors.append("knowledge_contradiction")
            report.steps_failed += 1

        # Synthesize improvement goals from all feedback
        report.improvement_goals = self._synthesize_goals(report)

        # Push synthesised goals to the SQLite queue
        for goal_dict in report.improvement_goals:
            try:
                self._queue.push(
                    ImprovementGoal(
                        goal=goal_dict["goal"],
                        source=goal_dict["source"],
                        priority=goal_dict["priority"],
                        context=goal_dict.get("context", {}),
                    )
                )
            except (sqlite3.Error, OSError) as exc:
                logger.debug("Failed to push synthesized goal: %s", exc)

        # Persist the legacy JSON queue
        self._queue.save(self._queue_path)

        logger.info(
            "feedback_orchestrator_complete cycle=%s goals=%d steps=%d/%d",
            cycle_id,
            report.goals_generated,
            report.steps_completed,
            report.steps_completed + report.steps_failed,
        )

        return report

    # --- Goal synthesis ---

    @staticmethod
    def _synthesize_goals(report: FeedbackReport) -> list[dict[str, Any]]:
        """Convert step outputs into prioritized ImprovementGoal dicts."""
        goals: list[dict[str, Any]] = []

        # Gauntlet failures -> fix goals
        for finding in report.gauntlet_findings:
            goals.append(
                {
                    "goal": f"Fix validation failure: {finding.get('description', 'unknown')[:120]}",
                    "source": "gauntlet_finding",
                    "priority": 0.9,
                    "context": finding.get("metadata", {}),
                }
            )

        # Introspection gaps -> agent improvement goals
        for gap in report.introspection_snapshot.get("gaps", []):
            agent = gap.get("metadata", {}).get("agent_name", "unknown")
            rate = gap.get("metadata", {}).get("success_rate", 0)
            goals.append(
                {
                    "goal": f"Improve agent {agent} performance (acceptance rate: {rate:.0%})",
                    "source": "introspection_gap",
                    "priority": 0.7,
                    "context": gap.get("metadata", {}),
                }
            )

        # Pulse trending -> timely priority goals
        for pulse in report.pulse_priorities:
            desc = pulse.get("description", "")
            goals.append(
                {
                    "goal": f"Address trending topic: {desc[:100]}",
                    "source": "pulse_trending",
                    "priority": 0.4,
                    "context": pulse.get("metadata", {}),
                }
            )

        return goals

    # --- Step implementations ---

    def _step_gauntlet(
        self,
        execution_results: list[dict[str, Any]],
    ) -> list[FeedbackGoal]:
        """Step 1: Run Gauntlet validation on execution receipts."""
        goals: list[FeedbackGoal] = []

        from aragora.gauntlet.runner import GauntletRunner

        runner = GauntletRunner()

        for er in execution_results:
            receipt_hash = er.get("receipt_hash")
            if not receipt_hash:
                continue

            files_changed = er.get("files_changed", [])
            if not files_changed:
                continue

            try:
                findings = runner.scan_files(files_changed)
                critical = [f for f in findings if f.severity in ("critical", "high")]

                if critical:
                    desc = f"Gauntlet found {len(critical)} critical findings in {', '.join(files_changed[:3])}"
                    goals.append(
                        FeedbackGoal(
                            description=desc,
                            source="gauntlet_finding",
                            track="security",
                            priority=1,
                            estimated_impact="high",
                            metadata={"receipt_hash": receipt_hash, "finding_count": len(critical)},
                        )
                    )
            except (RuntimeError, ValueError, OSError, AttributeError):
                continue

        return goals

    def _step_introspection(
        self,
        execution_results: list[dict[str, Any]],
    ) -> list[FeedbackGoal]:
        """Step 2: Capture agent performance and identify capability gaps."""
        goals: list[FeedbackGoal] = []

        from aragora.introspection.active import ActiveIntrospectionTracker

        tracker = ActiveIntrospectionTracker()
        summaries = tracker.get_all_summaries()

        for agent_name, summary in summaries.items():
            # Use proposal acceptance rate as a proxy for success
            success_rate = summary.proposal_acceptance_rate

            if success_rate < 0.5:
                goals.append(
                    FeedbackGoal(
                        description=(
                            f"Agent '{agent_name}' has low acceptance rate ({success_rate:.0%}). "
                            f"Consider retraining or replacing for this domain."
                        ),
                        source="introspection_gap",
                        track="core",
                        priority=3,
                        estimated_impact="medium",
                        metadata={"agent_name": agent_name, "success_rate": success_rate},
                    )
                )

        return goals

    def _step_genesis(
        self,
        execution_results: list[dict[str, Any]],
    ) -> int:
        """Step 3: Auto-breed improved agent configs when quality < threshold."""
        from aragora.genesis.breeding import PopulationManager

        manager = PopulationManager()

        # Check if any execution results show consistently poor quality
        failed_count = sum(1 for er in execution_results if not er.get("success"))
        total = len(execution_results)

        if total > 0 and failed_count / total > 0.5:
            # Get or create the active population and evolve it
            base_agents = list(
                {
                    er.get("agent_type", "claude")
                    for er in execution_results
                    if not er.get("success")
                }
            ) or ["claude"]
            population = manager.get_or_create_population(base_agents)
            evolved = manager.evolve_population(population)
            return len(evolved.genomes)

        return 0

    def _step_learning(
        self,
        cycle_id: str,
        execution_results: list[dict[str, Any]],
    ) -> int:
        """Step 4: Adjust hyperparameters based on cycle outcomes."""
        from aragora.learning.meta import LearningMetrics, MetaLearner

        learner = MetaLearner()

        # Build a LearningMetrics from cycle outcomes
        total = len(execution_results)
        if total == 0:
            return 0

        succeeded = sum(1 for er in execution_results if er.get("success"))
        retention_rate = succeeded / total if total else 0.5
        forgetting_rate = 1.0 - retention_rate

        metrics = LearningMetrics(
            pattern_retention_rate=retention_rate,
            forgetting_rate=forgetting_rate,
            prediction_accuracy=retention_rate,
            tier_efficiency={"fast": retention_rate, "slow": retention_rate},
        )

        adjustments = learner.adjust_hyperparameters(metrics)
        return len(adjustments)

    def _step_workspace(
        self,
        execution_results: list[dict[str, Any]],
    ) -> int:
        """Step 5: Deduplicate executed work via bead fingerprints.

        Uses a simple JSON fingerprint store colocated with the improvement
        queue.  The workspace.bead.BeadManager is async and requires complex
        NoMIC store initialisation, so we keep a lightweight sync store here.
        """
        import hashlib

        fp_path = (self._queue_path or _DEFAULT_QUEUE_PATH).parent / "bead_fingerprints.json"
        fp_path.parent.mkdir(parents=True, exist_ok=True)

        # Load existing fingerprints
        known: set[str] = set()
        if fp_path.exists():
            try:
                known = set(json.loads(fp_path.read_text(encoding="utf-8")))
            except (json.JSONDecodeError, TypeError):
                known = set()

        deduped = 0
        for er in execution_results:
            desc = er.get("subtask", "")
            files = er.get("files_changed", [])
            if desc and files:
                raw = f"{desc}:{','.join(sorted(files))}"
                fingerprint = hashlib.sha256(raw.encode()).hexdigest()
                if fingerprint in known:
                    deduped += 1
                else:
                    known.add(fingerprint)

        # Persist updated fingerprints
        fp_path.write_text(json.dumps(sorted(known), indent=2), encoding="utf-8")

        return deduped

    def _step_pulse(self) -> list[FeedbackGoal]:
        """Step 6: Inject trending topics from Pulse as timely priorities."""
        import asyncio

        goals: list[FeedbackGoal] = []

        from aragora.pulse.ingestor import PulseManager

        manager = PulseManager()

        # get_trending_topics is async; run in a sync context
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop and loop.is_running():
            import concurrent.futures

            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:
                trending = pool.submit(
                    asyncio.run,
                    manager.get_trending_topics(limit_per_platform=5),
                ).result(timeout=30)
        else:
            trending = asyncio.run(manager.get_trending_topics(limit_per_platform=5))

        for topic in trending:
            title = getattr(topic, "title", str(topic))
            category = getattr(topic, "category", "general")

            # Map Pulse categories to tracks
            track_map = {
                "security": "security",
                "ai": "core",
                "testing": "qa",
                "frontend": "sme",
                "devtools": "developer",
            }
            track = track_map.get(category, "core")

            goals.append(
                FeedbackGoal(
                    description=f"Trending: {title[:100]}",
                    source="pulse_trending",
                    track=track,
                    priority=4,
                    estimated_impact="low",
                    metadata={"category": category},
                )
            )

        return goals

    def _step_knowledge_contradiction(
        self,
        cycle_id: str,
    ) -> list[FeedbackGoal]:
        """Step 7: Detect contradictions in KnowledgeMound.

        Scans the 'nomic' workspace for conflicting knowledge items and
        generates feedback goals for high-severity contradictions so they
        can be resolved in the next improvement cycle.
        """
        import asyncio

        from aragora.knowledge.mound import get_knowledge_mound
        from aragora.knowledge.mound.ops.contradiction import (
            ContradictionDetector,
        )

        goals: list[FeedbackGoal] = []

        mound = get_knowledge_mound(workspace_id="nomic")
        detector = ContradictionDetector()

        # Run the async detection in a sync context
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        if loop and loop.is_running():
            # Already in an async context -- fall back to a new thread.
            import concurrent.futures

            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as pool:
                report = pool.submit(
                    asyncio.run,
                    detector.detect_contradictions(mound, workspace_id="nomic"),
                ).result(timeout=30)
        else:
            report = asyncio.run(detector.detect_contradictions(mound, workspace_id="nomic"))

        if report.contradictions_found == 0:
            logger.debug(
                "feedback_contradiction_scan cycle=%s clean",
                cycle_id,
            )
            return goals

        logger.info(
            "feedback_contradiction_scan cycle=%s found=%d by_severity=%s",
            cycle_id,
            report.contradictions_found,
            report.by_severity,
        )

        # Generate goals for medium+ severity contradictions
        for contradiction in report.contradictions:
            if contradiction.severity in ("low",):
                continue

            priority_map = {"critical": 1, "high": 2, "medium": 3}
            impact_map = {"critical": "high", "high": "high", "medium": "medium"}

            goals.append(
                FeedbackGoal(
                    description=(
                        f"KM contradiction ({contradiction.severity}): "
                        f"{contradiction.contradiction_type.value} conflict "
                        f"between items {contradiction.item_a_id} and "
                        f"{contradiction.item_b_id} "
                        f"(score={contradiction.conflict_score:.2f})"
                    ),
                    source="km_contradiction",
                    track="core",
                    priority=priority_map.get(contradiction.severity, 3),
                    estimated_impact=impact_map.get(contradiction.severity, "medium"),
                    metadata={
                        "contradiction_type": contradiction.contradiction_type.value,
                        "severity": contradiction.severity,
                        "conflict_score": contradiction.conflict_score,
                        "item_a_id": contradiction.item_a_id,
                        "item_b_id": contradiction.item_b_id,
                        "cycle_id": cycle_id,
                    },
                )
            )

        return goals[:10]  # Cap at 10 to avoid flooding the queue


__all__ = [
    "FeedbackGoal",
    "FeedbackReport",
    "FeedbackResult",
    "ImprovementGoal",
    "ImprovementQueue",
    "SelfImproveFeedbackOrchestrator",
]
