"""
Deterministic post-consensus output quality checks and upgrade prompts.

This module provides:
- Lightweight output contract derivation from tasks
- Deterministic validation of sectioned Markdown outputs
- Structured quality reports suitable for gating and telemetry
- Prompt construction for "upgrade-to-good" repair loops
"""

from __future__ import annotations

import json
import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Literal

from aragora.debate.repo_grounding import assess_repo_grounding


_HEADER_RE = re.compile(r"^(#{1,6})\s+(.+?)\s*$", re.MULTILINE)
_PATH_RE = re.compile(r"(?:^|[\s`])(?:/?[A-Za-z0-9_.-]+/)+[A-Za-z0-9_.-]+(?:$|[\s`])")
_THRESHOLD_LINE_RE = re.compile(
    r"(?i)(<=|>=|<|>|=|==)\s*\d+(?:\.\d+)?\s*(?:%|ms|s|sec|seconds|m|min|minutes|h|hours|rps|qps|req/s)?"
)
_JSON_BLOCK_RE = re.compile(r"```json\s*(.*?)```", re.DOTALL | re.IGNORECASE)
_GENERIC_CODE_BLOCK_RE = re.compile(r"```\s*(.*?)```", re.DOTALL)

# Known template strings produced by _default_section_content().
# Content matching these (after stripping) is filler, not real debate output.
_TEMPLATE_STRINGS: frozenset[str] = frozenset(
    {
        "- Prioritized task list with execution rationale.",
        "- Break top task into independently testable subtasks.",
        "- aragora/cli/commands/debate.py\n- tests/debate/test_output_quality.py",
        "- Run targeted unit tests and one smoke run for validation.",
        (
            "If error_rate > 2% for 10m, rollback by disabling the feature flag "
            "and redeploying the last stable build."
        ),
        (
            "If error_rate > 2% for 10m, rollback by disabling feature flag and "
            "redeploying last stable build."
        ),
        "- p95_latency <= 250ms for 15m\n- error_rate < 1% over 15m",
        "```json\n{}\n```",
        "- Fill in section content.",
    }
)

# Minimum word count for a section to be considered substantive.
_MIN_SUBSTANTIVE_WORDS = 10


def _normalize_heading(text: str) -> str:
    return re.sub(r"[^a-z0-9]+", " ", text.lower()).strip()


def _slugify(text: str) -> str:
    return re.sub(r"[^a-z0-9]+", "_", text.lower()).strip("_")


def _extract_sections(markdown: str) -> list[dict[str, Any]]:
    matches = list(_HEADER_RE.finditer(markdown))
    if not matches:
        return []

    sections: list[dict[str, Any]] = []
    for idx, match in enumerate(matches):
        title = match.group(2).strip()
        start = match.end()
        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(markdown)
        content = markdown[start:end].strip()
        sections.append(
            {
                "title": title,
                "normalized": _normalize_heading(title),
                "content": content,
                "level": len(match.group(1)),
                "start": match.start(),
                "end": end,
            }
        )
    return sections


@dataclass
class OutputContract:
    """Expected output structure for post-consensus validation."""

    required_sections: list[str] = field(default_factory=list)
    require_json_payload: bool = True
    require_gate_thresholds: bool = True
    require_rollback_triggers: bool = True
    require_owner_paths: bool = True
    require_repo_path_existence: bool = True
    require_practicality_checks: bool = True

    @property
    def normalized_sections(self) -> list[str]:
        return [_normalize_heading(section) for section in self.required_sections]

    def to_dict(self) -> dict[str, Any]:
        return {
            "required_sections": list(self.required_sections),
            "require_json_payload": self.require_json_payload,
            "require_gate_thresholds": self.require_gate_thresholds,
            "require_rollback_triggers": self.require_rollback_triggers,
            "require_owner_paths": self.require_owner_paths,
            "require_repo_path_existence": self.require_repo_path_existence,
            "require_practicality_checks": self.require_practicality_checks,
        }


def _coerce_bool(value: Any, *, field_name: str) -> bool:
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        normalized = value.strip().lower()
        if normalized in {"1", "true", "yes", "on"}:
            return True
        if normalized in {"0", "false", "no", "off"}:
            return False
    raise ValueError(f"Invalid boolean for {field_name}: {value!r}")


def output_contract_from_dict(data: dict[str, Any]) -> OutputContract:
    """Create an OutputContract from a JSON-compatible dict."""
    raw_sections = data.get("required_sections")
    if raw_sections is None and isinstance(data.get("sections"), list):
        raw_sections = data.get("sections")
    if not isinstance(raw_sections, list):
        raise ValueError("Output contract must include required_sections as a list.")

    sections: list[str] = []
    for item in raw_sections:
        if not isinstance(item, str) or not item.strip():
            raise ValueError("required_sections entries must be non-empty strings.")
        sections.append(item.strip())
    if not sections:
        raise ValueError("required_sections must not be empty.")

    def _flag(name: str, default: bool) -> bool:
        value = data.get(name, default)
        return _coerce_bool(value, field_name=name)

    return OutputContract(
        required_sections=sections,
        require_json_payload=_flag("require_json_payload", True),
        require_gate_thresholds=_flag("require_gate_thresholds", True),
        require_rollback_triggers=_flag("require_rollback_triggers", True),
        require_owner_paths=_flag("require_owner_paths", True),
        require_repo_path_existence=_flag("require_repo_path_existence", True),
        require_practicality_checks=_flag("require_practicality_checks", True),
    )


def load_output_contract_from_file(path: str) -> OutputContract:
    """Load OutputContract from a JSON file path."""
    file_path = Path(path).expanduser()
    try:
        raw_text = file_path.read_text(encoding="utf-8")
    except OSError as e:
        raise ValueError(f"Failed to read output contract file: {file_path} ({e})") from e

    try:
        parsed = json.loads(raw_text)
    except json.JSONDecodeError as e:
        raise ValueError(f"Output contract file must be valid JSON: {file_path} ({e.msg})") from e

    if not isinstance(parsed, dict):
        raise ValueError("Output contract root must be a JSON object.")
    return output_contract_from_dict(parsed)


@dataclass
class OutputQualityReport:
    """Deterministic report for contract compliance and practical usability."""

    verdict: Literal["good", "needs_work"]
    quality_score_10: float
    section_hits: dict[str, bool]
    section_count: int
    has_gate_thresholds: bool
    has_rollback_trigger: bool
    has_paths: bool
    has_valid_json_payload: bool
    practicality_score_10: float = 0.0
    path_existence_rate: float = 0.0
    placeholder_rate: float = 0.0
    first_batch_concreteness: float = 0.0
    existing_repo_paths: list[str] = field(default_factory=list)
    missing_repo_paths: list[str] = field(default_factory=list)
    placeholder_hits: list[str] = field(default_factory=list)
    duplicate_sections: list[str] = field(default_factory=list)
    empty_sections: list[str] = field(default_factory=list)
    defects: list[str] = field(default_factory=list)

    def to_dict(self) -> dict[str, Any]:
        return {
            "verdict": self.verdict,
            "quality_score_10": self.quality_score_10,
            "section_hits": dict(self.section_hits),
            "section_count": self.section_count,
            "has_gate_thresholds": self.has_gate_thresholds,
            "has_rollback_trigger": self.has_rollback_trigger,
            "has_paths": self.has_paths,
            "has_valid_json_payload": self.has_valid_json_payload,
            "practicality_score_10": self.practicality_score_10,
            "path_existence_rate": self.path_existence_rate,
            "placeholder_rate": self.placeholder_rate,
            "first_batch_concreteness": self.first_batch_concreteness,
            "existing_repo_paths": list(self.existing_repo_paths),
            "missing_repo_paths": list(self.missing_repo_paths),
            "placeholder_hits": list(self.placeholder_hits),
            "duplicate_sections": list(self.duplicate_sections),
            "empty_sections": list(self.empty_sections),
            "defects": list(self.defects),
        }


def derive_output_contract_from_task(task: str) -> OutputContract | None:
    """Infer a section contract from tasks that request explicit output sections."""
    if not task:
        return None

    match = None
    patterns = [
        r"(?is)\boutput\s+sections?\b\s*[:\-]?\s*(.+)",
        r"(?is)\bthese\s+sections?\b(?:\s+as\s+markdown\s+headers?)?\s*[:\-]\s*(.+)",
        r"(?is)\bsections?\s+as\s+markdown\s+headers?\s*[:\-]\s*(.+)",
        r"(?is)\brequired\s+sections?\s*[:\-]\s*(.+)",
    ]
    for pattern in patterns:
        candidate = re.search(pattern, task)
        if candidate:
            match = candidate
            break

    sections: list[str] = []
    if match:
        tail = match.group(1).strip()
        tail = re.split(r"[\n.]", tail, maxsplit=1)[0].strip()
        if tail:
            parts = [part.strip(" \t\r\n-") for part in re.split(r"[,;]", tail)]
            sections = [re.sub(r"(?i)^and\s+", "", part).strip() for part in parts if part]

    # Fallback: infer from known headings when the task embeds them in free-form prose.
    if not sections:
        known = [
            "Ranked High-Level Tasks",
            "Suggested Subtasks",
            "Owner module / file paths",
            "Test Plan",
            "Rollback Plan",
            "Gate Criteria",
            "JSON Payload",
        ]
        task_norm = task.lower()
        present = [name for name in known if name.lower() in task_norm]
        if len(present) >= 3:
            sections = sorted(present, key=lambda name: task_norm.find(name.lower()))

    if not sections:
        return None

    normalized = {_normalize_heading(section) for section in sections}
    return OutputContract(
        required_sections=sections,
        require_json_payload="json payload" in normalized,
        require_gate_thresholds=any(
            "gate criteria" in name or "acceptance criteria" in name for name in normalized
        ),
        require_rollback_triggers=any("rollback plan" in name for name in normalized),
        require_owner_paths=any(
            "owner module" in name or "file paths" in name or "owner module file paths" in name
            for name in normalized
        ),
        require_repo_path_existence=True,
        require_practicality_checks=True,
    )


def build_contract_context_block(contract: OutputContract) -> str:
    """Build deterministic pre-debate contract instructions from a parsed contract."""
    lines: list[str] = [
        "### Output Contract (Deterministic Quality Gates)",
        "Return exactly one markdown section for each required heading in the same order:",
    ]
    for idx, section in enumerate(contract.required_sections, start=1):
        lines.append(f"{idx}. {section}")

    lines.extend(
        [
            "",
            "Hard requirements:",
            "- Do not omit, rename, or duplicate required section headings.",
            "- Each required section must have substantive non-empty content.",
        ]
    )

    if contract.require_gate_thresholds:
        lines.append(
            "- Gate Criteria must include quantitative thresholds (explicit operators/values/units)."
        )
    if contract.require_rollback_triggers:
        lines.append("- Rollback Plan must include explicit trigger -> rollback action mapping.")
    if contract.require_owner_paths:
        lines.append("- Owner module / file paths must include concrete repository paths.")
    if contract.require_repo_path_existence:
        lines.append("- Referenced repository paths must exist in the current workspace.")
    if contract.require_practicality_checks:
        lines.append(
            "- First execution batch must be concrete (actionable, testable, and measurable)."
        )
    if contract.require_json_payload:
        lines.append(
            "- JSON Payload section must include a valid ```json``` block that mirrors section content."
        )

    return "\n".join(lines)


def _find_section_content(sections: list[dict[str, Any]], normalized_title: str) -> str:
    for section in sections:
        if section["normalized"] == normalized_title:
            return str(section["content"] or "")
    return ""


def _is_template_content(text: str) -> bool:
    """Return True if the text matches a known template/filler string."""
    stripped = text.strip()
    if stripped in _TEMPLATE_STRINGS:
        return True
    # Also check if the content is a single-line platitude
    for tmpl in _TEMPLATE_STRINGS:
        if stripped == tmpl.strip():
            return True
    return False


def _section_word_count(text: str) -> int:
    """Count meaningful words in a section (excluding markdown syntax)."""
    # Strip code blocks, bullet markers, and heading markers
    cleaned = re.sub(r"```.*?```", "", text, flags=re.DOTALL)
    cleaned = re.sub(r"^[#\-*>\s]+", "", cleaned, flags=re.MULTILINE)
    return len(cleaned.split())


def _has_rollback_trigger(text: str) -> bool:
    lowered = text.lower()
    if "rollback" not in lowered:
        return False
    has_trigger = any(token in lowered for token in ("if", "when", "trigger", "condition"))
    has_action = any(
        token in lowered for token in ("rollback", "revert", "disable", "restore", "redeploy")
    )
    return has_trigger and has_action


def _extract_json_payload(text: str) -> tuple[bool, str]:
    block = _JSON_BLOCK_RE.search(text) or _GENERIC_CODE_BLOCK_RE.search(text)
    if not block:
        return (False, "missing json code block")
    raw = block.group(1).strip()
    if not raw:
        return (False, "empty json code block")
    try:
        parsed = json.loads(raw)
    except json.JSONDecodeError as e:
        return (False, f"invalid json payload: {e.msg}")
    if not isinstance(parsed, (dict, list)):
        return (False, "json payload must be object or array")
    return (True, "")


def validate_output_against_contract(
    answer: str,
    contract: OutputContract,
    *,
    repo_root: str | None = None,
) -> OutputQualityReport:
    """Validate output quality against a deterministic contract."""
    answer = answer or ""
    sections = _extract_sections(answer)

    heading_counts: dict[str, int] = {}
    for section in sections:
        heading_counts[section["normalized"]] = heading_counts.get(section["normalized"], 0) + 1

    section_hits: dict[str, bool] = {}
    duplicate_sections: list[str] = []
    empty_sections: list[str] = []
    defects: list[str] = []

    required_normalized = contract.normalized_sections
    for original, normalized in zip(contract.required_sections, required_normalized, strict=False):
        key = _slugify(original)
        present = normalized in heading_counts
        section_hits[key] = present
        if not present:
            defects.append(f"Missing required section: {original}")
            continue

        if heading_counts.get(normalized, 0) > 1:
            duplicate_sections.append(original)
            defects.append(f"Duplicate section heading: {original}")

        content = _find_section_content(sections, normalized)
        if not content.strip():
            empty_sections.append(original)
            defects.append(f"Empty section content: {original}")
        elif _is_template_content(content):
            defects.append(f"Template filler detected in section: {original}")
        elif _section_word_count(content) < _MIN_SUBSTANTIVE_WORDS:
            # Skip word-count check for inherently terse sections
            terse_ok = (
                "json payload" in normalized or "file paths" in normalized or "owner" in normalized
            )
            if not terse_ok:
                defects.append(
                    f"Section too brief ({_section_word_count(content)} words): {original}"
                )

    # Count how many sections are template filler (for score penalty)
    template_section_count = 0
    for _orig, norm in zip(contract.required_sections, required_normalized, strict=False):
        content = _find_section_content(sections, norm)
        if content.strip() and _is_template_content(content):
            template_section_count += 1

    gate_text = _find_section_content(sections, _normalize_heading("Gate Criteria"))
    if not gate_text:
        gate_text = _find_section_content(sections, _normalize_heading("Acceptance Criteria"))
    has_gate_thresholds = bool(gate_text and len(_THRESHOLD_LINE_RE.findall(gate_text)) >= 2)

    rollback_text = _find_section_content(sections, _normalize_heading("Rollback Plan"))
    has_rollback_trigger = _has_rollback_trigger(rollback_text)

    owner_text = _find_section_content(sections, _normalize_heading("Owner module / file paths"))
    has_paths = bool(owner_text and _PATH_RE.search(owner_text))

    json_text = _find_section_content(sections, _normalize_heading("JSON Payload"))
    has_valid_json_payload, json_error = (
        _extract_json_payload(json_text) if json_text else (False, "")
    )

    grounding = assess_repo_grounding(
        answer,
        repo_root=repo_root,
        require_owner_paths=contract.require_owner_paths,
    )

    if contract.require_gate_thresholds and not has_gate_thresholds:
        defects.append("Gate Criteria is missing explicit quantitative thresholds.")
    if contract.require_rollback_triggers and not has_rollback_trigger:
        defects.append("Rollback Plan is missing explicit trigger -> action mapping.")
    if contract.require_owner_paths and not has_paths:
        defects.append("Owner module / file paths is missing concrete repo paths.")
    if contract.require_repo_path_existence and contract.require_owner_paths:
        if grounding.path_existence_rate < 0.67:
            defects.append("Owner module / file paths are weakly grounded to existing repo files.")
    if contract.require_practicality_checks and grounding.practicality_score_10 < 5.0:
        defects.append("Output practicality is too low for execution handoff.")
    if contract.require_json_payload and not has_valid_json_payload:
        defects.append(
            "JSON Payload is invalid or missing." + (f" ({json_error})" if json_error else "")
        )

    section_count = sum(1 for hit in section_hits.values() if hit)
    max_score = max(len(contract.required_sections) + 4, 1)
    raw_score = float(section_count)
    raw_score += 1.0 if has_gate_thresholds else 0.0
    raw_score += 1.0 if has_rollback_trigger else 0.0
    raw_score += 1.0 if has_paths else 0.0
    raw_score += 1.0 if has_valid_json_payload else 0.0

    # Penalize template filler: each template section removes 1 point from raw score.
    # This prevents deterministic repair from achieving a perfect score with filler.
    raw_score = max(0.0, raw_score - template_section_count)

    quality_score_10 = round(min(10.0, (raw_score / max_score) * 10.0), 2)

    verdict: Literal["good", "needs_work"] = "good"
    if defects or duplicate_sections or empty_sections:
        verdict = "needs_work"

    return OutputQualityReport(
        verdict=verdict,
        quality_score_10=quality_score_10,
        section_hits=section_hits,
        section_count=section_count,
        has_gate_thresholds=has_gate_thresholds,
        has_rollback_trigger=has_rollback_trigger,
        has_paths=has_paths,
        has_valid_json_payload=has_valid_json_payload,
        practicality_score_10=grounding.practicality_score_10,
        path_existence_rate=grounding.path_existence_rate,
        placeholder_rate=grounding.placeholder_rate,
        first_batch_concreteness=grounding.first_batch_concreteness,
        existing_repo_paths=grounding.existing_paths,
        missing_repo_paths=grounding.missing_paths,
        placeholder_hits=grounding.placeholder_hits,
        duplicate_sections=duplicate_sections,
        empty_sections=empty_sections,
        defects=defects,
    )


def build_upgrade_prompt(
    *,
    task: str,
    contract: OutputContract,
    current_answer: str,
    defects: list[str],
) -> str:
    """Build a focused repair prompt for the upgrade-to-good loop."""
    defect_lines = (
        "\n".join(f"- {defect}" for defect in defects) if defects else "- Improve clarity."
    )
    contract_lines = "\n".join(
        f"{idx}. {section}" for idx, section in enumerate(contract.required_sections, start=1)
    )
    hard_rules = build_contract_context_block(contract)

    return (
        "You are performing a post-consensus quality repair pass.\n"
        "Preserve intent, improve structure, and fix only quality defects.\n"
        "Return ONLY the revised markdown answer.\n\n"
        f"Task:\n{task}\n\n"
        "Required sections (exact order):\n"
        f"{contract_lines}\n\n"
        "Defects to fix:\n"
        f"{defect_lines}\n\n"
        f"{hard_rules}\n\n"
        "Current answer:\n"
        f"{current_answer}"
    )


def build_concretization_prompt(
    *,
    task: str,
    contract: OutputContract,
    current_answer: str,
    practicality_score_10: float,
    target_practicality_10: float,
    defects: list[str],
) -> str:
    """Build a focused prompt for post-consensus concretization/upgrading."""
    defect_lines = "\n".join(f"- {defect}" for defect in defects) if defects else "- None listed."
    contract_lines = "\n".join(
        f"{idx}. {section}" for idx, section in enumerate(contract.required_sections, start=1)
    )
    hard_rules = build_contract_context_block(contract)
    return (
        "You are performing a post-consensus concretization pass for execution readiness.\n"
        "Keep the core strategy, but make the first execution batch practical and testable.\n"
        "Return ONLY revised markdown output.\n\n"
        f"Task:\n{task}\n\n"
        f"Current practicality score (0-10): {practicality_score_10}\n"
        f"Target practicality score (0-10): {target_practicality_10}\n\n"
        "Required sections (exact order):\n"
        f"{contract_lines}\n\n"
        "Concretization requirements:\n"
        "- Replace placeholders ([NEW], [INFERRED], TBD, TODO) with concrete decisions.\n"
        "- First ranked tasks must include explicit file paths and measurable gate criteria.\n"
        "- Suggested subtasks must be independently testable.\n"
        "- Keep rollback trigger->action mappings explicit.\n"
        "- Keep JSON payload synchronized with revised sections.\n\n"
        "Defects to fix:\n"
        f"{defect_lines}\n\n"
        f"{hard_rules}\n\n"
        "Current answer:\n"
        f"{current_answer}"
    )


def _default_section_content(section_name: str) -> str:
    normalized = _normalize_heading(section_name)
    if "ranked high level tasks" in normalized:
        return "- Prioritized task list with execution rationale."
    if "suggested subtasks" in normalized:
        return "- Break top task into independently testable subtasks."
    if "owner module" in normalized or "file paths" in normalized:
        return "- aragora/cli/commands/debate.py\n- tests/debate/test_output_quality.py"
    if "test plan" in normalized:
        return "- Run targeted unit tests and one smoke run for validation."
    if "rollback plan" in normalized:
        return (
            "If error_rate > 2% for 10m, rollback by disabling the feature flag "
            "and redeploying the last stable build."
        )
    if "gate criteria" in normalized or "acceptance criteria" in normalized:
        return "- p95_latency <= 250ms for 15m\n- error_rate < 1% over 15m"
    if "json payload" in normalized:
        return "```json\n{}\n```"
    return "- Fill in section content."


def _lines_for_json(section_text: str) -> list[str]:
    lines = [line.strip(" -\t") for line in section_text.splitlines() if line.strip()]
    return lines[:5] if lines else []


def _build_json_payload_from_answer(answer: str, contract: OutputContract) -> dict[str, Any]:
    sections = _extract_sections(answer or "")
    payload: dict[str, Any] = {}
    required_names = contract.required_sections
    required_norm = contract.normalized_sections

    json_name = next(
        (n for n in required_names if "json payload" in _normalize_heading(n)),
        None,
    )
    json_norm = _normalize_heading(json_name) if json_name else ""

    for section_name, section_norm in zip(required_names, required_norm, strict=False):
        if section_norm == json_norm:
            continue
        section_text = _find_section_content(sections, section_norm).strip()
        payload[_slugify(section_name)] = _lines_for_json(section_text)

    dissent_lines: list[str] = []
    unresolved_lines: list[str] = []
    for section in sections:
        normalized = section["normalized"]
        content = str(section["content"] or "")
        lines = _lines_for_json(content)
        if not lines:
            continue
        if "dissent" in normalized:
            dissent_lines.extend(lines)
        if "unresolved" in normalized and "risk" in normalized:
            unresolved_lines.extend(lines)

    if dissent_lines:
        payload["dissent"] = dissent_lines[:10]
    if unresolved_lines:
        payload["unresolved_risks"] = unresolved_lines[:10]

    payload["quality_json_finalized"] = True
    return payload


def finalize_json_payload(answer: str, contract: OutputContract) -> str:
    """Ensure JSON Payload section exists and contains valid JSON."""
    if not contract.require_json_payload:
        return answer

    text = answer or ""
    required_names = contract.required_sections
    json_name = next(
        (n for n in required_names if "json payload" in _normalize_heading(n)),
        None,
    )
    if not json_name:
        return text

    json_norm = _normalize_heading(json_name)
    payload = _build_json_payload_from_answer(answer, contract)
    json_block = "```json\n" + json.dumps(payload, indent=2) + "\n```"

    sections = _extract_sections(text)
    json_sections = [section for section in sections if section["normalized"] == json_norm]
    if json_sections:
        # Collapse duplicate JSON payload sections first (keep first).
        if len(json_sections) > 1:
            for extra in reversed(json_sections[1:]):
                text = text[: extra["start"]].rstrip() + "\n\n" + text[extra["end"] :].lstrip()
            sections = _extract_sections(text)
            json_sections = [section for section in sections if section["normalized"] == json_norm]

        primary = json_sections[0]
        header_match = _HEADER_RE.match(text, primary["start"])
        if header_match:
            header_line = header_match.group(0).strip()
            return (
                text[: primary["start"]] + f"{header_line}\n{json_block}\n" + text[primary["end"] :]
            )

    joined = text.rstrip()
    suffix = f"\n\n## {json_name}\n{json_block}\n"
    return (joined + suffix).lstrip("\n")


def apply_deterministic_quality_repairs(
    answer: str,
    contract: OutputContract,
    report: OutputQualityReport,
) -> str:
    """Apply deterministic last-mile repairs for common structured-output defects.

    CRITICAL DESIGN: This function is ADDITIVE, not destructive.
    - It preserves the entire original answer as the base.
    - It only APPENDS missing required sections that the debate didn't produce.
    - It never replaces real debate content with template filler.
    - For structural fixes (missing gate thresholds, paths, rollback), it
      appends to existing section content rather than replacing it.
    """
    text = (answer or "").rstrip()
    if not text:
        return text

    sections = _extract_sections(text)
    section_by_norm: dict[str, str] = {}
    for section in sections:
        section_by_norm[section["normalized"]] = str(section["content"] or "").strip()

    required_names = contract.required_sections
    required_norm = contract.normalized_sections

    # Identify which required sections are genuinely missing.
    missing_sections: list[tuple[str, str]] = []
    for name, normalized in zip(required_names, required_norm, strict=False):
        if normalized not in section_by_norm or not section_by_norm[normalized].strip():
            missing_sections.append((name, normalized))

    # Only append missing sections — never discard existing content.
    appended_parts: list[str] = []
    for name, _normalized in missing_sections:
        # Skip JSON Payload from missing-section appending; handled separately below.
        if "json payload" in _normalize_heading(name):
            continue
        appended_parts.append(
            f"\n\n## {name}\n*[Section not produced by debate — requires LLM concretization pass]*"
        )

    # Structural fixes: append supplemental content to existing sections
    # without replacing what the debate produced.
    owner_name = next(
        (
            n
            for n in required_names
            if "owner module" in _normalize_heading(n) or "file paths" in _normalize_heading(n)
        ),
        None,
    )
    gate_name = next(
        (
            n
            for n in required_names
            if "gate criteria" in _normalize_heading(n)
            or "acceptance criteria" in _normalize_heading(n)
        ),
        None,
    )
    rollback_name = next(
        (n for n in required_names if "rollback plan" in _normalize_heading(n)),
        None,
    )
    json_name = next(
        (n for n in required_names if "json payload" in _normalize_heading(n)),
        None,
    )

    # For existing sections that lack required structural elements,
    # find and patch them in-place.
    if owner_name and contract.require_owner_paths:
        owner_norm = _normalize_heading(owner_name)
        owner_content = section_by_norm.get(owner_norm, "")
        if owner_content and not _PATH_RE.search(owner_content):
            # The section exists but has no paths — append a note.
            text = _append_to_section(
                text,
                owner_norm,
                "\n- *[No repo paths detected — add concrete file paths]*",
            )

    if gate_name and contract.require_gate_thresholds:
        gate_norm = _normalize_heading(gate_name)
        gate_content = section_by_norm.get(gate_norm, "")
        if gate_content and len(_THRESHOLD_LINE_RE.findall(gate_content)) < 2:
            text = _append_to_section(
                text,
                gate_norm,
                "\n- *[Insufficient quantitative thresholds — add measurable gates]*",
            )

    if rollback_name and contract.require_rollback_triggers:
        rollback_norm = _normalize_heading(rollback_name)
        rollback_content = section_by_norm.get(rollback_norm, "")
        if rollback_content and not _has_rollback_trigger(rollback_content):
            text = _append_to_section(
                text,
                rollback_norm,
                "\n- *[Missing explicit trigger → action mapping]*",
            )

    # JSON payload: build from actual section content, not templates.
    if json_name and contract.require_json_payload:
        # Re-extract sections from the (possibly amended) text.
        updated_sections = _extract_sections(text)
        payload = _build_json_payload_from_answer(text, contract)
        json_block = "```json\n" + json.dumps(payload, indent=2) + "\n```"

        json_norm = _normalize_heading(json_name)
        json_present = any(s["normalized"] == json_norm for s in updated_sections)
        if not json_present:
            appended_parts.append(f"\n\n## {json_name}\n{json_block}")

    result = text + "".join(appended_parts)
    return result.strip() + "\n"


def _append_to_section(text: str, section_norm: str, suffix: str) -> str:
    """Append text to the end of an existing section, before the next section header."""
    sections = _extract_sections(text)
    for section in sections:
        if section["normalized"] == section_norm:
            insert_pos = section["end"]
            return text[:insert_pos].rstrip() + suffix + "\n" + text[insert_pos:]
    return text
