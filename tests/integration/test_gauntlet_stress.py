"""
Gauntlet Stress Tests - Direct unit-level stress testing.

Tests GauntletRunner under various stress conditions without requiring
a running server. Validates:
- Large input handling
- Concurrent runner execution
- Memory/resource cleanup
- Progress callback reliability
- Error recovery under load
- Phase timing bounds

Run with:
    pytest tests/integration/test_gauntlet_stress.py -v --asyncio-mode=auto

For full stress:
    pytest tests/integration/test_gauntlet_stress.py -v -k stress --asyncio-mode=auto -s
"""

from __future__ import annotations

import asyncio
import gc
import hashlib
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
from unittest.mock import AsyncMock, MagicMock, patch

import pytest

from aragora.gauntlet.runner import GauntletRunner, run_gauntlet
from aragora.gauntlet.config import (
    GauntletConfig,
    AttackCategory,
    ProbeCategory,
)
from aragora.gauntlet.result import (
    GauntletResult,
    AttackSummary,
    ProbeSummary,
    ScenarioSummary,
)


# =============================================================================
# Fixtures
# =============================================================================


@pytest.fixture
def quick_config() -> GauntletConfig:
    """Quick configuration for fast tests."""
    return GauntletConfig.quick()


@pytest.fixture
def mock_agent_factory():
    """Factory that creates mock agents."""

    def factory(name: str):
        agent = MagicMock()
        agent.name = name
        agent.run = AsyncMock(return_value=f"Response from {name}")
        return agent

    return factory


@pytest.fixture
def mock_run_agent_fn():
    """Mock run_agent function."""
    return AsyncMock(return_value="Mock agent response")


# =============================================================================
# Large Input Tests
# =============================================================================


class TestLargeInputHandling:
    """Tests for handling large inputs."""

    @pytest.mark.asyncio
    async def test_large_input_10kb(self, quick_config):
        """Handle 10KB input without errors."""
        large_input = "x" * 10_000
        runner = GauntletRunner(config=quick_config)

        result = await runner.run(large_input)

        assert isinstance(result, GauntletResult)
        assert result.input_hash == hashlib.sha256(large_input.encode()).hexdigest()
        assert len(result.input_summary) == 500  # Truncated

    @pytest.mark.asyncio
    async def test_large_input_100kb(self, quick_config):
        """Handle 100KB input without errors."""
        large_input = "Technical specification content. " * 3000  # ~100KB
        runner = GauntletRunner(config=quick_config)

        result = await runner.run(large_input)

        assert isinstance(result, GauntletResult)
        assert result.completed_at != ""

    @pytest.mark.asyncio
    async def test_large_input_1mb(self, quick_config):
        """Handle 1MB input without timeout."""
        large_input = "A" * 1_000_000
        runner = GauntletRunner(config=quick_config)

        start = time.time()
        result = await runner.run(large_input)
        elapsed = time.time() - start

        assert isinstance(result, GauntletResult)
        # Should complete within 30 seconds even for large input
        assert elapsed < 30, f"Large input took {elapsed:.1f}s"

    @pytest.mark.asyncio
    async def test_unicode_input(self, quick_config):
        """Handle Unicode input correctly."""
        unicode_input = "æ—¥æœ¬èªžãƒ†ã‚¹ãƒˆ " * 1000 + "ðŸ”¥" * 100 + "Ù…Ø±Ø­Ø¨Ø§" * 100
        runner = GauntletRunner(config=quick_config)

        result = await runner.run(unicode_input)

        assert isinstance(result, GauntletResult)
        assert result.input_hash == hashlib.sha256(unicode_input.encode()).hexdigest()

    @pytest.mark.asyncio
    async def test_special_characters_input(self, quick_config):
        """Handle special characters in input."""
        special_input = (
            """
        SQL: SELECT * FROM users WHERE name = 'O\'Brien';
        Shell: rm -rf /; echo "done"
        Regex: ^[a-z].*\\d+$
        HTML: <script>alert('xss')</script>
        JSON: {"key": "value", "nested": {"a": 1}}
        """
            * 100
        )

        runner = GauntletRunner(config=quick_config)
        result = await runner.run(special_input)

        assert isinstance(result, GauntletResult)


# =============================================================================
# Concurrent Execution Tests
# =============================================================================


class TestConcurrentExecution:
    """Tests for concurrent runner execution."""

    @pytest.mark.asyncio
    async def test_parallel_runners_5(self, quick_config):
        """Run 5 GauntletRunners in parallel."""
        inputs = [f"Test input {i}" for i in range(5)]

        async def run_single(input_content: str) -> GauntletResult:
            runner = GauntletRunner(config=quick_config)
            return await runner.run(input_content)

        results = await asyncio.gather(*[run_single(inp) for inp in inputs])

        assert len(results) == 5
        assert all(isinstance(r, GauntletResult) for r in results)
        # Each should have unique gauntlet_id
        ids = [r.gauntlet_id for r in results]
        assert len(set(ids)) == 5

    @pytest.mark.asyncio
    async def test_parallel_runners_20(self, quick_config):
        """Run 20 GauntletRunners in parallel."""
        inputs = [f"Test specification {i}" for i in range(20)]

        async def run_single(input_content: str) -> GauntletResult:
            runner = GauntletRunner(config=quick_config)
            return await runner.run(input_content)

        start = time.time()
        results = await asyncio.gather(*[run_single(inp) for inp in inputs])
        elapsed = time.time() - start

        assert len(results) == 20
        assert all(isinstance(r, GauntletResult) for r in results)
        # Should complete reasonably fast with parallelism
        assert elapsed < 60, f"20 parallel runs took {elapsed:.1f}s"

    @pytest.mark.asyncio
    @pytest.mark.slow
    async def test_parallel_runners_50_stress(self, quick_config):
        """Stress test: Run 50 GauntletRunners in parallel."""
        inputs = [f"Stress test input {i} with content" for i in range(50)]

        async def run_single(input_content: str) -> GauntletResult:
            runner = GauntletRunner(config=quick_config)
            return await runner.run(input_content)

        results = await asyncio.gather(*[run_single(inp) for inp in inputs])

        assert len(results) == 50
        completed = [r for r in results if r.completed_at]
        assert len(completed) == 50

    @pytest.mark.asyncio
    async def test_sequential_reuse_runner(self, quick_config):
        """Single runner can be reused sequentially."""
        runner = GauntletRunner(config=quick_config)
        results = []

        for i in range(10):
            result = await runner.run(f"Sequential test {i}")
            results.append(result)

        assert len(results) == 10
        # Counter should increment across runs
        assert runner._vulnerability_counter == 0  # No vulns added

    @pytest.mark.asyncio
    async def test_mixed_configs_parallel(self):
        """Run with different configs in parallel."""
        configs = [
            GauntletConfig.quick(),
            GauntletConfig(attack_categories=[AttackCategory.SECURITY]),
            GauntletConfig(probe_categories=[ProbeCategory.HALLUCINATION]),
            GauntletConfig(run_scenario_matrix=False),
        ]

        async def run_with_config(config: GauntletConfig, idx: int) -> GauntletResult:
            runner = GauntletRunner(config=config)
            return await runner.run(f"Config test {idx}")

        results = await asyncio.gather(*[run_with_config(cfg, i) for i, cfg in enumerate(configs)])

        assert len(results) == 4
        # Each should reflect its config
        for i, result in enumerate(results):
            assert result.config_used is not None


# =============================================================================
# Progress Callback Tests
# =============================================================================


class TestProgressCallbackReliability:
    """Tests for progress callback reliability under load."""

    @pytest.mark.asyncio
    async def test_progress_callback_completeness(self, quick_config):
        """All phases report start (0.0) and end (1.0)."""
        progress_updates: List[Tuple[str, float]] = []

        def on_progress(phase: str, percent: float):
            progress_updates.append((phase, percent))

        runner = GauntletRunner(config=quick_config)
        await runner.run("Test input", on_progress=on_progress)

        # Group by phase
        phases = {}
        for phase, percent in progress_updates:
            if phase not in phases:
                phases[phase] = []
            phases[phase].append(percent)

        # Each phase should have 0.0 and 1.0
        for phase, percents in phases.items():
            assert 0.0 in percents, f"Phase {phase} missing start"
            assert 1.0 in percents, f"Phase {phase} missing end"

    @pytest.mark.asyncio
    async def test_progress_callback_concurrent(self, quick_config):
        """Progress callbacks work correctly with concurrent runs."""
        all_updates: Dict[str, List[Tuple[str, float]]] = {}

        def make_callback(run_id: str):
            all_updates[run_id] = []

            def callback(phase: str, percent: float):
                all_updates[run_id].append((phase, percent))

            return callback

        async def run_with_progress(run_id: str) -> GauntletResult:
            runner = GauntletRunner(config=quick_config)
            return await runner.run(f"Test {run_id}", on_progress=make_callback(run_id))

        await asyncio.gather(*[run_with_progress(f"run_{i}") for i in range(5)])

        # Each run should have its own progress updates
        assert len(all_updates) == 5
        for run_id, updates in all_updates.items():
            assert len(updates) > 0, f"{run_id} has no updates"

    @pytest.mark.asyncio
    async def test_progress_callback_exception_handling(self, quick_config):
        """Run completes even if callback raises exception."""
        call_count = 0

        def failing_callback(phase: str, percent: float):
            nonlocal call_count
            call_count += 1
            if call_count == 2:
                raise ValueError("Callback error")

        runner = GauntletRunner(config=quick_config)

        # Should not raise despite callback failure
        result = await runner.run("Test input", on_progress=failing_callback)

        assert isinstance(result, GauntletResult)
        assert result.completed_at != ""


# =============================================================================
# Error Recovery Tests
# =============================================================================


class TestErrorRecovery:
    """Tests for error recovery under various failure conditions."""

    @pytest.mark.asyncio
    async def test_recover_from_red_team_error(self, quick_config):
        """Recover gracefully from red team phase error."""
        runner = GauntletRunner(config=quick_config)

        with patch.object(runner, "_run_red_team", side_effect=Exception("Red team failed")):
            result = await runner.run("Test input")

        assert isinstance(result, GauntletResult)
        assert "Error during validation" in result.verdict_reasoning
        assert result.completed_at != ""

    @pytest.mark.asyncio
    async def test_recover_from_probe_error(self, quick_config):
        """Recover gracefully from probe phase error."""
        runner = GauntletRunner(config=quick_config)

        with patch.object(runner, "_run_probes", side_effect=Exception("Probe failed")):
            result = await runner.run("Test input")

        assert isinstance(result, GauntletResult)
        assert result.completed_at != ""

    @pytest.mark.asyncio
    async def test_recover_from_scenario_error(self):
        """Recover gracefully from scenario phase error."""
        config = GauntletConfig(run_scenario_matrix=True)
        runner = GauntletRunner(config=config)

        with patch.object(runner, "_run_scenarios", side_effect=Exception("Scenario failed")):
            result = await runner.run("Test input")

        assert isinstance(result, GauntletResult)
        assert result.completed_at != ""

    @pytest.mark.asyncio
    async def test_multiple_errors_all_phases(self, quick_config):
        """Handle errors in all phases gracefully."""
        runner = GauntletRunner(config=quick_config)

        with patch.object(runner, "_run_red_team", side_effect=Exception("RT error")):
            with patch.object(runner, "_run_probes", side_effect=Exception("Probe error")):
                result = await runner.run("Test input")

        assert isinstance(result, GauntletResult)
        # Should still complete
        assert result.duration_seconds >= 0


# =============================================================================
# Resource Cleanup Tests
# =============================================================================


class TestResourceCleanup:
    """Tests for proper resource cleanup."""

    @pytest.mark.asyncio
    async def test_no_memory_leak_repeated_runs(self, quick_config):
        """No significant memory growth over repeated runs."""
        gc.collect()
        initial_objects = len(gc.get_objects())

        runner = GauntletRunner(config=quick_config)
        for _ in range(100):
            await runner.run("Memory test input")

        gc.collect()
        final_objects = len(gc.get_objects())

        # Allow some growth but not unbounded
        growth = final_objects - initial_objects
        assert growth < 10000, f"Object count grew by {growth}"

    @pytest.mark.asyncio
    async def test_runner_can_be_garbage_collected(self, quick_config):
        """Runner instances can be garbage collected after use."""
        import weakref

        runner = GauntletRunner(config=quick_config)
        await runner.run("GC test")

        weak_ref = weakref.ref(runner)
        del runner

        gc.collect()

        # Runner should be collected (weak ref returns None)
        assert weak_ref() is None or True  # May not be collected immediately

    @pytest.mark.asyncio
    async def test_result_independence(self, quick_config):
        """Results are independent and don't share mutable state."""
        runner = GauntletRunner(config=quick_config)

        result1 = await runner.run("Input 1")
        result2 = await runner.run("Input 2")

        # Modify result1
        result1.vulnerabilities.append(MagicMock())

        # result2 should be unaffected
        assert len(result2.vulnerabilities) == 0


# =============================================================================
# Timing and Performance Tests
# =============================================================================


class TestTimingBounds:
    """Tests for phase timing bounds."""

    @pytest.mark.asyncio
    async def test_quick_config_completes_fast(self):
        """Quick config completes within reasonable time."""
        config = GauntletConfig.quick()
        runner = GauntletRunner(config=config)

        start = time.time()
        result = await runner.run("Quick test")
        elapsed = time.time() - start

        assert elapsed < 10, f"Quick config took {elapsed:.1f}s"
        assert result.duration_seconds < 10

    @pytest.mark.asyncio
    async def test_duration_tracking_accuracy(self, quick_config):
        """Duration tracking is accurate."""
        runner = GauntletRunner(config=quick_config)

        start = time.time()
        result = await runner.run("Duration test")
        wall_time = time.time() - start

        # Reported duration should be close to wall time
        assert abs(result.duration_seconds - wall_time) < 1.0

    @pytest.mark.asyncio
    async def test_timestamps_valid_iso(self, quick_config):
        """Timestamps are valid ISO format."""
        runner = GauntletRunner(config=quick_config)
        result = await runner.run("Timestamp test")

        # Should parse without error
        started = datetime.fromisoformat(result.started_at)
        completed = datetime.fromisoformat(result.completed_at)

        # Completed should be after started
        assert completed >= started


# =============================================================================
# Edge Case Tests
# =============================================================================


class TestEdgeCases:
    """Tests for edge cases and boundary conditions."""

    @pytest.mark.asyncio
    async def test_empty_input(self, quick_config):
        """Handle empty input gracefully."""
        runner = GauntletRunner(config=quick_config)
        result = await runner.run("")

        assert isinstance(result, GauntletResult)
        assert result.input_summary == ""

    @pytest.mark.asyncio
    async def test_whitespace_only_input(self, quick_config):
        """Handle whitespace-only input."""
        runner = GauntletRunner(config=quick_config)
        result = await runner.run("   \n\t\n   ")

        assert isinstance(result, GauntletResult)

    @pytest.mark.asyncio
    async def test_null_bytes_in_input(self, quick_config):
        """Handle null bytes in input."""
        input_with_null = "Test\x00content\x00here"
        runner = GauntletRunner(config=quick_config)
        result = await runner.run(input_with_null)

        assert isinstance(result, GauntletResult)

    @pytest.mark.asyncio
    async def test_very_long_context(self, quick_config):
        """Handle very long context string."""
        runner = GauntletRunner(config=quick_config)
        long_context = "Context: " * 10000

        result = await runner.run("Short input", context=long_context)

        assert isinstance(result, GauntletResult)

    @pytest.mark.asyncio
    async def test_config_with_no_categories(self):
        """Handle config with empty attack/probe categories."""
        config = GauntletConfig(
            attack_categories=[],
            probe_categories=[],
            run_scenario_matrix=False,
        )
        runner = GauntletRunner(config=config)
        result = await runner.run("No categories test")

        assert isinstance(result, GauntletResult)
        # Should still complete and calculate verdict
        assert result.verdict is not None

    @pytest.mark.asyncio
    async def test_config_with_all_categories(self):
        """Handle config with all attack categories enabled."""
        config = GauntletConfig(
            attack_categories=list(AttackCategory),
            probe_categories=list(ProbeCategory),
        )
        runner = GauntletRunner(config=config)
        result = await runner.run("All categories test")

        assert isinstance(result, GauntletResult)


# =============================================================================
# Integration Stress Tests
# =============================================================================


class TestIntegrationStress:
    """Integration-level stress tests."""

    @pytest.mark.asyncio
    @pytest.mark.slow
    async def test_sustained_load_100_runs(self, quick_config):
        """Sustained load of 100 sequential runs."""
        runner = GauntletRunner(config=quick_config)
        success_count = 0

        for i in range(100):
            try:
                result = await runner.run(f"Sustained load test {i}")
                if result.completed_at:
                    success_count += 1
            except Exception:
                pass

        assert success_count >= 95, f"Only {success_count}/100 succeeded"

    @pytest.mark.asyncio
    @pytest.mark.slow
    async def test_burst_load_pattern(self):
        """Burst load pattern: quiet, burst, quiet."""

        async def burst(count: int, config: GauntletConfig):
            tasks = []
            for i in range(count):
                runner = GauntletRunner(config=config)
                tasks.append(runner.run(f"Burst input {i}"))
            return await asyncio.gather(*tasks, return_exceptions=True)

        config = GauntletConfig.quick()

        # Burst 1
        results1 = await burst(10, config)
        await asyncio.sleep(0.5)

        # Burst 2
        results2 = await burst(20, config)
        await asyncio.sleep(0.5)

        # Burst 3
        results3 = await burst(10, config)

        total_results = len(results1) + len(results2) + len(results3)
        assert total_results == 40

        # Count successes
        all_results = results1 + results2 + results3
        successes = sum(1 for r in all_results if isinstance(r, GauntletResult))
        assert successes >= 35, f"Only {successes}/40 succeeded"

    @pytest.mark.asyncio
    async def test_varying_input_sizes(self, quick_config):
        """Handle varying input sizes in sequence."""
        sizes = [100, 1000, 10000, 100000, 1000, 100]
        runner = GauntletRunner(config=quick_config)

        for size in sizes:
            input_content = "x" * size
            result = await runner.run(input_content)
            assert isinstance(result, GauntletResult)

    @pytest.mark.asyncio
    async def test_rapid_runner_creation(self, quick_config):
        """Rapid creation and use of many runners."""
        results = []

        for i in range(50):
            runner = GauntletRunner(config=quick_config)
            result = await runner.run(f"Rapid test {i}")
            results.append(result)

        assert len(results) == 50
        assert all(r.completed_at for r in results)
