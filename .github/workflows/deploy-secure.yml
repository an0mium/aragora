name: Deploy (Secure)

# This workflow uses AWS OIDC authentication instead of long-lived SSH keys.
# It provides:
# - No long-lived credentials stored in GitHub secrets
# - Temporary, scoped credentials via STS AssumeRoleWithWebIdentity
# - Audit trail in AWS CloudTrail
# - Fine-grained IAM permissions
# - Production deployment approval gates via GitHub Environments
#
# Prerequisites:
# 1. Create OIDC identity provider in AWS IAM (see docs/CI_CD_SECURITY.md)
# 2. Create IAM role with trust policy (deploy/aws/oidc-trust-policy.json)
# 3. Attach permissions policy (deploy/aws/deploy-role-policy.json)
# 4. Install SSM agent on target instances
# 5. Set repository secrets: AWS_ACCOUNT_ID, AWS_DEPLOY_ROLE_NAME
# 6. Configure environment protection: Settings > Environments > production > Required reviewers

on:
  push:
    branches: [main]
    paths:
      - 'aragora/**'
      - 'deploy/**'
      - 'requirements.txt'
      - 'pyproject.toml'
      - '.github/workflows/deploy-secure.yml'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - cloudflare
          - ec2-staging
          - ec2-production

concurrency:
  group: deploy-secure-${{ github.ref }}
  cancel-in-progress: false

permissions:
  id-token: write   # Required for OIDC
  contents: read

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install -e ".[dev]"
          pip install pytest-timeout httpx

      - name: Run quick tests
        run: |
          pytest tests/test_handlers_debates.py tests/test_api_handler.py \
            --timeout=60 -x --tb=short
        env:
          PYTHONPATH: .

  deploy-cloudflare:
    needs: test
    if: github.event.inputs.environment == 'all' || github.event.inputs.environment == 'cloudflare' || github.event_name == 'push'
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: 'npm'
          cache-dependency-path: aragora/live/package-lock.json

      - name: Install dependencies
        working-directory: aragora/live
        run: npm ci

      - name: Build frontend (static export)
        working-directory: aragora/live
        run: npm run build:export

      - name: Verify static export
        working-directory: aragora/live
        run: |
          if [ ! -f out/index.html ]; then
            echo "::error::index.html not found in out/ directory"
            ls -la out/ | head -20
            exit 1
          fi
          echo "Static export contains $(find out -name '*.html' | wc -l) HTML files"

      - name: Deploy to Cloudflare Pages
        working-directory: aragora/live
        run: |
          npx wrangler pages deploy out --project-name=aragora --commit-dirty=true
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}

  deploy-ec2-staging:
    needs: test
    if: github.event.inputs.environment == 'all' || github.event.inputs.environment == 'ec2-staging' || github.event_name == 'push'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    environment: staging

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ secrets.AWS_DEPLOY_ROLE_NAME }}
          role-session-name: github-actions-deploy-${{ github.run_id }}
          aws-region: us-east-2

      - name: Get staging instance IDs
        id: get-instance
        run: |
          # Get ALL staging instances (not just the first one)
          INSTANCE_IDS=$(aws ec2 describe-instances \
            --filters "Name=tag:Environment,Values=staging" "Name=tag:Application,Values=aragora" "Name=instance-state-name,Values=running" \
            --query 'Reservations[].Instances[].InstanceId' \
            --output text)

          if [ -z "$INSTANCE_IDS" ] || [ "$INSTANCE_IDS" == "None" ]; then
            echo "::error::No staging instances found with tags Environment=staging, Application=aragora"
            exit 1
          fi

          # Convert whitespace-separated IDs to comma-separated for SSM
          INSTANCE_IDS_CSV=$(echo "$INSTANCE_IDS" | tr '\t\n' ',' | sed 's/,$//')
          FIRST_ID=$(echo "$INSTANCE_IDS" | awk '{print $1}')
          COUNT=$(echo "$INSTANCE_IDS" | wc -w | tr -d ' ')

          echo "instance_id=$FIRST_ID" >> $GITHUB_OUTPUT
          echo "instance_ids=$INSTANCE_IDS_CSV" >> $GITHUB_OUTPUT
          echo "Found $COUNT staging instance(s): $INSTANCE_IDS_CSV"

      - name: Deploy via SSM
        id: deploy
        run: |
          # Send deployment command via SSM Run Command to ALL staging instances
          IFS=',' read -ra IDS <<< "${{ steps.get-instance.outputs.instance_ids }}"
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "${IDS[@]}" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy aragora from GitHub Actions run ${{ github.run_id }}" \
            --parameters 'commands=[
              "set -e",
              "export HOME=/root",
              "cd /home/ec2-user/aragora",
              "git config --global --add safe.directory /home/ec2-user/aragora",
              "PREVIOUS_COMMIT=$(git rev-parse HEAD)",
              "echo \"Rollback point: $PREVIOUS_COMMIT\" > /tmp/aragora_deploy_state",
              "sudo -u ec2-user git stash --include-untracked || true",
              "sudo chown -R ec2-user:ec2-user /home/ec2-user/aragora/.git || true",
              "sudo -u ec2-user git fetch origin main",
              "sudo -u ec2-user git checkout main || sudo -u ec2-user git checkout -b main origin/main",
              "sudo -u ec2-user git reset --hard origin/main",
              "source venv/bin/activate",
              "echo \"Cleaning corrupted pip distributions...\"",
              "find venv/lib/python3.11/site-packages -maxdepth 1 -name '~*' -type d -exec rm -rf {} + 2>/dev/null || true",
              "pip install -e . --quiet --no-cache-dir",
              "find venv/lib/python3.11/site-packages -maxdepth 1 -name '~*' -type d -exec rm -rf {} + 2>/dev/null || true",
              "python -c \"from aragora.server.unified_server import UnifiedServer; print(\\\"Import OK\\\")\"",
              "echo \"Setting up secrets manager for systemd...\"",
              "sudo mkdir -p /etc/systemd/system/aragora.service.d/",
              "echo \"[Service]\" | sudo tee /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_USE_SECRETS_MANAGER=true\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=AWS_REGION=us-east-2\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_SECRET_NAME=aragora/staging\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_DB_BACKEND=postgres\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_ENV=staging\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_SECRETS_STRICT=false\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "sudo systemctl daemon-reload",
              "echo \"Initializing PostgreSQL stores...\"",
              "export ARAGORA_USE_SECRETS_MANAGER=true",
              "export AWS_REGION=us-east-2",
              "export ARAGORA_SECRET_NAME=aragora/staging",
              "export ARAGORA_ENV=staging",
              "export ARAGORA_SECRETS_STRICT=false",
              "python scripts/init_postgres_db.py || echo \"PostgreSQL init skipped (may not be configured)\"",
              "sudo systemctl restart aragora",
              "sleep 8",
              "if ! systemctl is-active --quiet aragora; then echo \"=== SERVICE FAILED ===\"; echo \"Status:\"; systemctl status aragora --no-pager || true; echo \"Recent logs:\"; journalctl -u aragora -n 50 --no-pager || true; exit 1; fi",
              "python scripts/seed_agents.py || echo \"Seed skipped (non-fatal)\"",
              "python scripts/validate_production.py --quick || echo \"Validation warnings (non-fatal)\"",
              "echo \"Deploy complete\""
            ]' \
            --timeout-seconds 300 \
            --query 'Command.CommandId' \
            --output text)

          echo "command_id=$COMMAND_ID" >> $GITHUB_OUTPUT
          echo "Started deployment command: $COMMAND_ID"

          # Poll for command completion (up to 5 minutes)
          for i in {1..60}; do
            RESULT=$(aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
              --query 'Status' \
              --output text 2>/dev/null || echo "Pending")

            if [[ "$RESULT" == "Success" ]] || [[ "$RESULT" == "Failed" ]] || [[ "$RESULT" == "Cancelled" ]] || [[ "$RESULT" == "TimedOut" ]]; then
              break
            fi
            echo "Waiting for SSM command... attempt $i/60 (status: $RESULT)"
            sleep 5
          done

          # Get final command result
          RESULT=$(aws ssm get-command-invocation \
            --command-id "$COMMAND_ID" \
            --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
            --query '[Status, StatusDetails]' \
            --output text)

          echo "Command result: $RESULT"

          if [[ "$RESULT" == *"Success"* ]]; then
            echo "deploy_success=true" >> $GITHUB_OUTPUT
          else
            echo "deploy_success=false" >> $GITHUB_OUTPUT
            # Get output for debugging
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
              --query 'StandardOutputContent' \
              --output text || true
            aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
              --query 'StandardErrorContent' \
              --output text || true
          fi

      - name: Verify deployment health
        id: health
        if: steps.deploy.outputs.deploy_success == 'true'
        run: |
          # Health check via SSM (security groups block direct IP access from GitHub Actions)
          echo "Checking health via SSM on instance..."

          HEALTH_CMD_ID=$(aws ssm send-command \
            --instance-ids "${{ steps.get-instance.outputs.instance_id }}" \
            --document-name "AWS-RunShellScript" \
            --comment "Health check from GitHub Actions run ${{ github.run_id }}" \
            --parameters 'commands=[
              "for i in $(seq 1 12); do if curl -sf http://localhost:8080/api/health; then echo; echo HEALTH_OK; exit 0; fi; echo \"Waiting for server... attempt $i/12\"; sleep 5; done; echo HEALTH_FAIL; exit 1"
            ]' \
            --timeout-seconds 90 \
            --query 'Command.CommandId' \
            --output text)

          # Poll for health check completion
          for i in {1..20}; do
            STATUS=$(aws ssm get-command-invocation \
              --command-id "$HEALTH_CMD_ID" \
              --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
              --query 'Status' \
              --output text 2>/dev/null || echo "Pending")

            if [[ "$STATUS" == "Success" ]]; then
              echo "Health check passed (via SSM localhost)"
              echo "health_ok=true" >> $GITHUB_OUTPUT
              exit 0
            elif [[ "$STATUS" == "Failed" ]] || [[ "$STATUS" == "TimedOut" ]]; then
              break
            fi
            sleep 5
          done

          echo "health_ok=false" >> $GITHUB_OUTPUT
          echo "::warning::Health check failed (status: $STATUS)"

      - name: Verify external access via Cloudflare
        id: external_health
        if: steps.health.outputs.health_ok == 'true'
        run: |
          echo "Checking external access via Cloudflare..."
          for i in {1..6}; do
            RESPONSE=$(curl -sf "https://api.aragora.ai/api/health" 2>/dev/null || echo "")
            if echo "$RESPONSE" | jq -e '.status == "healthy"' > /dev/null 2>&1; then
              echo "External health check passed via Cloudflare"
              echo "external_ok=true" >> $GITHUB_OUTPUT
              exit 0
            fi
            echo "Waiting for Cloudflare... attempt $i/6"
            sleep 10
          done
          echo "::warning::External health check via Cloudflare failed"
          echo "external_ok=false" >> $GITHUB_OUTPUT

      - name: Rollback on failure
        if: steps.deploy.outputs.deploy_success != 'true' || steps.health.outputs.health_ok == 'false'
        run: |
          echo "::warning::Deployment failed - initiating rollback"

          aws ssm send-command \
            --instance-ids "${{ steps.get-instance.outputs.instance_id }}" \
            --document-name "AWS-RunShellScript" \
            --comment "Rollback aragora from GitHub Actions run ${{ github.run_id }}" \
            --parameters 'commands=[
              "set -e",
              "export HOME=/root",
              "cd /home/ec2-user/aragora",
              "git config --global --add safe.directory /home/ec2-user/aragora",
              "if [ -f /tmp/aragora_deploy_state ]; then source /tmp/aragora_deploy_state; fi",
              "if [ -n \"$PREVIOUS_COMMIT\" ]; then sudo -u ec2-user git checkout $PREVIOUS_COMMIT; fi",
              "source venv/bin/activate",
              "pip install -e . --quiet --no-cache-dir",
              "sudo systemctl restart aragora",
              "rm -f /tmp/aragora_deploy_state",
              "echo \"Rollback complete\""
            ]' \
            --timeout-seconds 120

  deploy-ec2-production:
    needs: [test, deploy-ec2-staging]
    # Run if: manual dispatch to production OR (staging succeeded AND auto-deploy)
    # NOTE: The 'environment: production' setting enables GitHub Environment Protection Rules.
    # Configure required reviewers in: Settings > Environments > production > Required reviewers
    if: |
      always() && (
        (github.event.inputs.environment == 'ec2-production') ||
        (needs.deploy-ec2-staging.result == 'success' && (github.event.inputs.environment == 'all' || github.event_name == 'push'))
      )
    runs-on: ubuntu-latest
    timeout-minutes: 20
    environment:
      name: production
      url: https://api.aragora.ai

    steps:
      - name: Production deployment notice
        run: |
          echo "::notice::PRODUCTION DEPLOYMENT - This deployment will affect api.aragora.ai"
          echo ""
          echo "## ðŸš€ Production Deployment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Staging result:** ${{ needs.deploy-ec2-staging.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âš ï¸ **This deployment requires approval.** Configure required reviewers in repository settings." >> $GITHUB_STEP_SUMMARY

      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ secrets.AWS_DEPLOY_ROLE_NAME }}
          role-session-name: github-actions-deploy-prod-${{ github.run_id }}
          aws-region: us-east-2

      - name: Get production instance IDs
        id: get-instance
        run: |
          # Get ALL production instances (not just the first one)
          INSTANCE_IDS=$(aws ec2 describe-instances \
            --filters "Name=tag:Environment,Values=production" "Name=tag:Application,Values=aragora" "Name=instance-state-name,Values=running" \
            --query 'Reservations[].Instances[].InstanceId' \
            --output text)

          if [ -z "$INSTANCE_IDS" ] || [ "$INSTANCE_IDS" == "None" ]; then
            echo "::error::No production instances found"
            exit 1
          fi

          # Convert whitespace-separated IDs to comma-separated for SSM
          INSTANCE_IDS_CSV=$(echo "$INSTANCE_IDS" | tr '\t\n' ',' | sed 's/,$//')
          FIRST_ID=$(echo "$INSTANCE_IDS" | awk '{print $1}')
          COUNT=$(echo "$INSTANCE_IDS" | wc -w | tr -d ' ')

          echo "instance_id=$FIRST_ID" >> $GITHUB_OUTPUT
          echo "instance_ids=$INSTANCE_IDS_CSV" >> $GITHUB_OUTPUT
          echo "Found $COUNT production instance(s): $INSTANCE_IDS_CSV"

      - name: Pre-deploy instance health check
        run: |
          echo "Verifying instance health before deployment..."
          IFS=',' read -ra IDS <<< "${{ steps.get-instance.outputs.instance_ids }}"
          for INST_ID in "${IDS[@]}"; do
            STATUS=$(aws ec2 describe-instance-status \
              --instance-ids "$INST_ID" \
              --query 'InstanceStatuses[0].[InstanceStatus.Status, SystemStatus.Status]' \
              --output text 2>/dev/null || echo "unknown unknown")
            INST_STATUS=$(echo "$STATUS" | awk '{print $1}')
            SYS_STATUS=$(echo "$STATUS" | awk '{print $2}')
            if [[ "$INST_STATUS" != "ok" ]] || [[ "$SYS_STATUS" != "ok" ]]; then
              echo "::error::Instance $INST_ID health check failed: instance=$INST_STATUS system=$SYS_STATUS (expected: ok/ok)"
              exit 1
            fi
            echo "Instance $INST_ID: instance=$INST_STATUS system=$SYS_STATUS"
          done
          echo "All instances healthy"

      - name: Deploy via SSM
        run: |
          # Deploy to ALL production instances
          IFS=',' read -ra IDS <<< "${{ steps.get-instance.outputs.instance_ids }}"
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "${IDS[@]}" \
            --document-name "AWS-RunShellScript" \
            --comment "Deploy aragora PRODUCTION from GitHub Actions run ${{ github.run_id }}" \
            --parameters 'commands=[
              "set -e",
              "export HOME=/root",
              "cd /home/ec2-user/aragora",
              "git config --global --add safe.directory /home/ec2-user/aragora",
              "PREVIOUS_COMMIT=$(git rev-parse HEAD)",
              "echo \"Rollback point: $PREVIOUS_COMMIT\" > /tmp/aragora_deploy_state",
              "sudo -u ec2-user git stash --include-untracked || true",
              "sudo chown -R ec2-user:ec2-user /home/ec2-user/aragora/.git || true",
              "sudo -u ec2-user git fetch origin main",
              "sudo -u ec2-user git checkout main || sudo -u ec2-user git checkout -b main origin/main",
              "sudo -u ec2-user git reset --hard origin/main",
              "source venv/bin/activate",
              "echo \"Cleaning corrupted pip distributions...\"",
              "find venv/lib/python3.11/site-packages -maxdepth 1 -name '~*' -type d -exec rm -rf {} + 2>/dev/null || true",
              "pip install -e . --quiet --no-cache-dir",
              "find venv/lib/python3.11/site-packages -maxdepth 1 -name '~*' -type d -exec rm -rf {} + 2>/dev/null || true",
              "python -c \"from aragora.server.unified_server import UnifiedServer; print(\\\"Import OK\\\")\"",
              "echo \"Setting up secrets manager for systemd...\"",
              "sudo mkdir -p /etc/systemd/system/aragora.service.d/",
              "echo \"[Service]\" | sudo tee /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_USE_SECRETS_MANAGER=true\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=AWS_REGION=us-east-2\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_SECRET_NAME=aragora/production\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_DB_BACKEND=postgres\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_ENV=production\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "echo \"Environment=ARAGORA_SECRETS_STRICT=true\" | sudo tee -a /etc/systemd/system/aragora.service.d/secrets.conf",
              "sudo systemctl daemon-reload",
              "echo \"Initializing PostgreSQL stores...\"",
              "export ARAGORA_USE_SECRETS_MANAGER=true",
              "export AWS_REGION=us-east-2",
              "export ARAGORA_SECRET_NAME=aragora/production",
              "export ARAGORA_ENV=production",
              "export ARAGORA_SECRETS_STRICT=true",
              "python scripts/init_postgres_db.py || echo \"PostgreSQL init skipped (may not be configured)\"",
              "sudo systemctl restart aragora",
              "sleep 8",
              "if ! systemctl is-active --quiet aragora; then echo \"=== SERVICE FAILED ===\"; echo \"Status:\"; systemctl status aragora --no-pager || true; echo \"Recent logs:\"; journalctl -u aragora -n 50 --no-pager || true; exit 1; fi",
              "python scripts/seed_agents.py || echo \"Seed skipped (non-fatal)\"",
              "python scripts/validate_production.py --quick || echo \"Validation warnings (non-fatal)\"",
              "echo \"Production deploy complete\""
            ]' \
            --timeout-seconds 300 \
            --query 'Command.CommandId' \
            --output text)

          # Poll for command completion (up to 5 minutes)
          for i in {1..60}; do
            STATUS=$(aws ssm get-command-invocation \
              --command-id "$COMMAND_ID" \
              --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
              --query 'Status' \
              --output text 2>/dev/null || echo "Pending")

            if [[ "$STATUS" == "Success" ]]; then
              echo "Production deploy completed successfully"
              exit 0
            elif [[ "$STATUS" == "Failed" ]] || [[ "$STATUS" == "Cancelled" ]] || [[ "$STATUS" == "TimedOut" ]]; then
              echo "::error::Production deploy failed with status: $STATUS"
              echo "=== SSM STDOUT ==="
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
                --query 'StandardOutputContent' \
                --output text || true
              echo "=== SSM STDERR ==="
              aws ssm get-command-invocation \
                --command-id "$COMMAND_ID" \
                --instance-id "${{ steps.get-instance.outputs.instance_id }}" \
                --query 'StandardErrorContent' \
                --output text || true
              exit 1
            fi
            echo "Waiting for SSM command... attempt $i/60 (status: $STATUS)"
            sleep 5
          done
          echo "::error::Production deploy timed out"
          exit 1

  notify:
    needs: [deploy-cloudflare, deploy-ec2-staging, deploy-ec2-production]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Summarize deployment status
        run: |
          echo "## Secure Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Target | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Cloudflare Pages | ${{ needs.deploy-cloudflare.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| EC2 Staging | ${{ needs.deploy-ec2-staging.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| EC2 Production | ${{ needs.deploy-ec2-production.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Authentication:** AWS OIDC (no long-lived secrets)" >> $GITHUB_STEP_SUMMARY
          echo "**Execution:** SSM Run Command (no SSH keys)" >> $GITHUB_STEP_SUMMARY
