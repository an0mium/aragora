# Aragora Honest Assessment (Evidence-Scoped)

> Last updated: February 26, 2026
> Scope: repository-grounded assessment, not external certification.

---

## Why This Exists

This document is intentionally conservative. It separates:

- What is clearly implemented and usable now
- What is partially proven and needs focused validation
- What should be presented as roadmap rather than current capability

If a claim is not easy to verify from the codebase, tests, or reproducible commands, it should not be used in external messaging.

---

## Snapshot (Verified in Repo)

- Runtime agent registry: **43** available agent types (`list_available_agents()`).
- Debate subsystem size: **247 Python files** under `aragora/debate`.
- Nomic subsystem size: **71,000+ Python LOC** under `aragora/nomic`.
- SDK namespace files: **186 Python files** and **184 TypeScript files** in SDK namespace directories.
  - Note: exported client namespace counts can differ slightly from raw file counts.

These figures are implementation snapshots, not guarantees of runtime throughput.

---

## What Is Real and Defensible

### 1. Multi-Agent Adversarial Decision Flow

The core debate engine is implemented and production-usable:

- Multiple model providers are supported.
- Structured propose/critique/synthesize style workflows are implemented.
- Consensus and dissent are represented explicitly rather than hidden.
- Decision receipts are generated with cryptographic integrity fields.

Defensible positioning:
"Aragora provides adversarial multi-agent decision vetting with traceable outputs."

### 2. Operational Delivery Surface

The platform exposes real operator surfaces:

- CLI workflows (`review`, `gauntlet`, debate-oriented commands)
- API handlers and WebSocket streaming surfaces
- SDKs for Python and TypeScript

Defensible positioning:
"Aragora is not just a demo loop; it has operator-facing CLI/API/SDK delivery paths."

### 3. Enterprise-Oriented Foundations Exist

Core enterprise subsystems are present in code:

- Authentication and SSO-related modules
- Authorization (RBAC/permission enforcement)
- Tenancy, billing, observability, and audit-related paths
- Security controls such as encryption and request hardening layers

Defensible positioning:
"Enterprise controls are first-class implementation areas, not post-hoc wrappers."

---

## What Is Partially Proven (Needs Qualification)

### 1. Autonomous Self-Improvement End-to-End

There is substantial self-improvement infrastructure in `aragora/nomic`, but claims about fully autonomous closed-loop improvement should remain qualified unless proven by repeatable end-to-end runs.

Recommended wording:
"Aragora includes a large self-improvement framework and coordination primitives; end-to-end autonomous operation is improving and should be validated per deployment."

### 2. Massive Parallel Swarm Execution

Many agent types are available, but practical parallelism is constrained by:

- Provider rate limits
- Queueing/scheduler behavior
- CI capacity and branch protection bottlenecks

Recommended wording:
"Aragora supports broad heterogeneous agent composition; effective parallelism depends on provider and CI constraints."

### 3. Compliance Posture Language

Feature support is not equivalent to formal certification.

Recommended wording:
"Aragora provides technical controls and evidence artifacts that support compliance programs; certification depends on organizational process and third-party audit."

---

## What Should Be Avoided in External Messaging

- "Immutable blockchain receipts" unless on-chain persistence is actually deployed and audited.
- Precise percentages without reproducible benchmark artifacts.
- Fixed large counts (permissions, resource types, parity %) unless generated by a tracked script in CI.
- "Fully autonomous self-improvement in production" without repeatable proof runs.

---

## Defensible Value Proposition

Aragora is strongest when positioned as:

1. Decision integrity infrastructure (not a generic chatbot framework)
2. Adversarial multi-model vetting with explicit dissent trails
3. Audit-ready, reproducible decision artifacts
4. BYOK economics (platform value independent of inference markup)

This is clearer and more defensible than competing on generic "agent orchestration" claims.

---

## Priority Hardening Plan

### Next 30 Days

1. Create a `docs/metrics_snapshot.md` generated from scripts for agent/SDK/subsystem counts.
2. Add a CI job that fails docs if key metrics drift without update.
3. Define one canonical wording block for compliance posture and reuse it across docs.

### Next 90 Days

1. Publish reproducible benchmarks for decision quality and convergence behavior.
2. Publish an end-to-end self-improvement validation report with pass/fail criteria.
3. Publish 2-3 public case studies with before/after decision outcomes.

---

## Bottom Line

Aragora has a real technical core and a credible differentiation: adversarial multi-agent decision vetting with traceable outputs.

The fastest way to strengthen trust is disciplined claims:

- keep externally stated metrics script-verifiable,
- separate capability from certification,
- and publish repeatable validation artifacts for contested claims.

That approach preserves velocity while improving credibility.
