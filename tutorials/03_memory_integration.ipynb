{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Memory Integration\n",
    "\n",
    "Learn how Aragora's memory systems help improve debates over time.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Using CritiqueStore to learn from past debates\n",
    "- Multi-tier memory (Continuum) for context retention\n",
    "- Pattern recognition and retrieval\n",
    "- ELO rankings for agent skill tracking\n",
    "\n",
    "**Time:** ~10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from aragora import Arena, Environment, DebateProtocol\n",
    "from aragora.agents.base import create_agent\n",
    "from aragora.memory.store import CritiqueStore\n",
    "from aragora.memory.continuum import ContinuumMemory\n",
    "from aragora.ranking.elo import ELOTracker\n",
    "\n",
    "print(\"Memory modules loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CritiqueStore: Learning from Past Debates\n",
    "\n",
    "The CritiqueStore persists debate outcomes and extracts patterns that can improve future debates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a critique store (uses SQLite by default)\n",
    "store = CritiqueStore(\"tutorial_memory.db\")\n",
    "\n",
    "# Check statistics\n",
    "stats = store.get_stats()\n",
    "print(\"CritiqueStore Statistics:\")\n",
    "print(f\"  Total debates: {stats['total_debates']}\")\n",
    "print(f\"  Consensus reached: {stats['consensus_debates']}\")\n",
    "print(f\"  Total patterns: {stats['total_patterns']}\")\n",
    "print(f\"  Avg confidence: {stats['avg_consensus_confidence']:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Debates with Memory\n",
    "\n",
    "When you pass a CritiqueStore to the Arena, it automatically stores results and learns patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents\n",
    "agents = [\n",
    "    create_agent(\"anthropic-api\", \"claude\", \"proposer\"),\n",
    "    create_agent(\"openai-api\", \"gpt\", \"critic\")\n",
    "]\n",
    "\n",
    "# Create environment\n",
    "env = Environment(\n",
    "    task=\"What's the best approach for database schema versioning?\"\n",
    ")\n",
    "\n",
    "# Create protocol\n",
    "protocol = DebateProtocol(rounds=2, consensus=\"majority\")\n",
    "\n",
    "# Run debate WITH memory\n",
    "arena = Arena(env, agents, protocol, memory=store)\n",
    "result = await arena.run()\n",
    "\n",
    "# Store the result\n",
    "store.store_debate(result)\n",
    "\n",
    "print(f\"Debate stored! Consensus: {result.consensus_reached}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Learned Patterns\n",
    "\n",
    "Patterns are extracted from debates and can be used to inform future discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve patterns\n",
    "patterns = store.retrieve_patterns(\n",
    "    issue_type=\"architecture\",  # Filter by type\n",
    "    min_success=1,               # Minimum times pattern was successful\n",
    "    limit=5                      # Max patterns to return\n",
    ")\n",
    "\n",
    "print(f\"Found {len(patterns)} patterns:\")\n",
    "for p in patterns:\n",
    "    print(f\"\\n  [{p.issue_type}] Success: {p.success_count}\")\n",
    "    print(f\"  Issue: {p.issue_text[:60]}...\")\n",
    "    if p.suggestion_text:\n",
    "        print(f\"  Fix: {p.suggestion_text[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuum Memory: Multi-Tier Context\n",
    "\n",
    "ContinuumMemory provides multiple tiers for different retention periods:\n",
    "\n",
    "| Tier | TTL | Purpose |\n",
    "|------|-----|--------|\n",
    "| Fast | 1 min | Immediate context |\n",
    "| Medium | 1 hour | Session memory |\n",
    "| Slow | 1 day | Cross-session learning |\n",
    "| Glacial | 1 week | Long-term patterns |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-tier memory\n",
    "continuum = ContinuumMemory()\n",
    "\n",
    "# Store data in different tiers\n",
    "continuum.store(\n",
    "    key=\"current_task\",\n",
    "    value={\"task\": \"Design a rate limiter\", \"started\": \"2024-01-01\"},\n",
    "    tier=\"fast\"  # Will expire in 1 minute\n",
    ")\n",
    "\n",
    "continuum.store(\n",
    "    key=\"session_context\",\n",
    "    value={\"project\": \"E-commerce API\", \"team\": \"Backend\"},\n",
    "    tier=\"medium\"  # Will expire in 1 hour\n",
    ")\n",
    "\n",
    "continuum.store(\n",
    "    key=\"learned_pattern\",\n",
    "    value={\"pattern\": \"Token bucket is preferred for rate limiting\"},\n",
    "    tier=\"slow\"  # Will expire in 1 day\n",
    ")\n",
    "\n",
    "print(\"Data stored in multiple tiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data (searches all tiers by default)\n",
    "current = continuum.retrieve(\"current_task\")\n",
    "print(f\"Current task: {current}\")\n",
    "\n",
    "# Retrieve from specific tier\n",
    "pattern = continuum.retrieve(\"learned_pattern\", tier=\"slow\")\n",
    "print(f\"Learned pattern: {pattern}\")\n",
    "\n",
    "# Search across tiers\n",
    "results = continuum.search(\"rate\", limit=5)\n",
    "print(f\"\\nSearch results for 'rate': {len(results)} matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Context for Debates\n",
    "\n",
    "Use `get_context()` to retrieve relevant memory for a new task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get context relevant to a new task\n",
    "context = continuum.get_context(\n",
    "    task=\"Design an API rate limiter for high traffic\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "print(\"Relevant context retrieved:\")\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELO Rankings: Agent Skill Tracking\n",
    "\n",
    "ELO rankings track agent performance over time, helping select the best agents for tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ELO tracker\n",
    "elo = ELOTracker(db_path=\"tutorial_elo.db\")\n",
    "\n",
    "# Get current rankings\n",
    "rankings = elo.get_rankings()\n",
    "\n",
    "print(\"Agent ELO Rankings:\")\n",
    "print(\"=\" * 40)\n",
    "for agent, rating in rankings[:10]:\n",
    "    print(f\"  {agent:20} {rating:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record a debate outcome\n",
    "elo.record_debate(\n",
    "    winner=\"claude-proposer\",\n",
    "    loser=\"gpt-critic\",\n",
    "    draw=False  # Set to True for ties\n",
    ")\n",
    "\n",
    "# Get updated rankings\n",
    "print(\"Updated rankings after debate:\")\n",
    "for agent, rating in elo.get_rankings()[:5]:\n",
    "    print(f\"  {agent}: {rating:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting It All Together\n",
    "\n",
    "Run a debate with full memory integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get context from previous debates\n",
    "historical_context = store.get_relevant_context(\n",
    "    task=\"Design an authentication system\",\n",
    "    limit=3\n",
    ")\n",
    "\n",
    "# Create environment with context\n",
    "env = Environment(\n",
    "    task=\"Design an authentication system for a mobile banking app\",\n",
    "    context=f\"Previous learnings: {historical_context}\"\n",
    ")\n",
    "\n",
    "# Create arena with memory\n",
    "arena = Arena(env, agents, protocol, memory=store)\n",
    "\n",
    "# Run debate\n",
    "result = await arena.run()\n",
    "\n",
    "# Store result and update ELO\n",
    "store.store_debate(result)\n",
    "if result.consensus_reached:\n",
    "    elo.record_debate(\n",
    "        winner=result.winning_agent,\n",
    "        loser=result.dissenting_agents[0] if result.dissenting_agents else None\n",
    "    )\n",
    "\n",
    "print(f\"\\nDebate complete with memory integration!\")\n",
    "print(f\"Consensus: {result.consensus_reached}\")\n",
    "print(f\"Stored to CritiqueStore and updated ELO rankings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Tutorial 4**: Deploy Aragora in production\n",
    "- **Tutorial 5**: Advanced features (Gauntlet, WebSocket streaming)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
